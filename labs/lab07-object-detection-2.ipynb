{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 7: Object Detection - Part 2\n",
        "## NMS, Fine-tuning, and Evaluation\n",
        "\n",
        "**Duration**: ~3 hours\n",
        "\n",
        "### Learning Objectives\n",
        "By the end of this lab, you will be able to:\n",
        "1. Understand and implement Non-Maximum Suppression (NMS)\n",
        "2. Prepare custom datasets for YOLO training\n",
        "3. Fine-tune YOLO on your own data\n",
        "4. Evaluate detection models with mAP\n",
        "\n",
        "### Prerequisites\n",
        "- Completed Lab 6 (Object Detection basics)\n",
        "\n",
        "### GPU Recommendation\n",
        "Fine-tuning YOLO benefits significantly from GPU. We recommend using Google Colab with GPU for Part 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# !pip install ultralytics supervision opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 1: Non-Maximum Suppression (NMS)\n",
        "\n",
        "## The Problem: Duplicate Detections\n",
        "\n",
        "Object detectors often output multiple overlapping boxes for the same object:\n",
        "\n",
        "```\n",
        "BEFORE NMS:                    AFTER NMS:\n",
        "\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚               â”‚             â”‚\n",
        "â”‚â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚â”‚               â”‚    ğŸ•       â”‚\n",
        "â”‚â”‚â”‚  ğŸ•     â”‚â”‚â”‚       â†’       â”‚   (0.95)    â”‚\n",
        "â”‚â”‚â”‚ (0.95)  â”‚â”‚â”‚               â”‚             â”‚\n",
        "â”‚â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "Multiple boxes              One best box\n",
        "(0.95, 0.90, 0.85)         (0.95)\n",
        "```\n",
        "\n",
        "**NMS keeps the best box and removes overlapping duplicates.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: IoU Calculation (from Lab 6)\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    \"\"\"Calculate IoU between two boxes in xyxy format.\"\"\"\n",
        "    x1_1, y1_1, x2_1, y2_1 = box1\n",
        "    x1_2, y1_2, x2_2, y2_2 = box2\n",
        "    \n",
        "    x1_i = max(x1_1, x1_2)\n",
        "    y1_i = max(y1_1, y1_2)\n",
        "    x2_i = min(x2_1, x2_2)\n",
        "    y2_i = min(y2_1, y2_2)\n",
        "    \n",
        "    if x2_i < x1_i or y2_i < y1_i:\n",
        "        intersection = 0\n",
        "    else:\n",
        "        intersection = (x2_i - x1_i) * (y2_i - y1_i)\n",
        "    \n",
        "    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "    union = area1 + area2 - intersection\n",
        "    \n",
        "    return intersection / union if union > 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: NMS Algorithm\n",
        "\n",
        "def nms(boxes, scores, iou_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Non-Maximum Suppression.\n",
        "    \n",
        "    Args:\n",
        "        boxes: List of boxes in xyxy format\n",
        "        scores: List of confidence scores\n",
        "        iou_threshold: Remove boxes with IoU > threshold\n",
        "    \n",
        "    Returns:\n",
        "        List of indices to keep\n",
        "    \"\"\"\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "    \n",
        "    # Sort by confidence (descending)\n",
        "    sorted_indices = np.argsort(scores)[::-1]\n",
        "    \n",
        "    keep = []\n",
        "    \n",
        "    while len(sorted_indices) > 0:\n",
        "        # Pick the box with highest confidence\n",
        "        best_idx = sorted_indices[0]\n",
        "        keep.append(best_idx)\n",
        "        \n",
        "        # Compare with remaining boxes\n",
        "        remaining_indices = []\n",
        "        for idx in sorted_indices[1:]:\n",
        "            iou = calculate_iou(boxes[best_idx], boxes[idx])\n",
        "            \n",
        "            # Keep if IoU is below threshold (not overlapping too much)\n",
        "            if iou < iou_threshold:\n",
        "                remaining_indices.append(idx)\n",
        "        \n",
        "        sorted_indices = remaining_indices\n",
        "    \n",
        "    return keep\n",
        "\n",
        "# Test\n",
        "boxes = [\n",
        "    (100, 100, 200, 200),  # Box 0\n",
        "    (110, 110, 210, 210),  # Box 1 (overlaps with 0)\n",
        "    (105, 105, 205, 205),  # Box 2 (overlaps with 0 and 1)\n",
        "    (300, 300, 400, 400),  # Box 3 (separate)\n",
        "]\n",
        "scores = [0.95, 0.90, 0.85, 0.80]\n",
        "\n",
        "keep_indices = nms(boxes, scores, iou_threshold=0.5)\n",
        "print(f\"Original boxes: {len(boxes)}\")\n",
        "print(f\"Kept indices: {keep_indices}\")\n",
        "print(f\"Boxes after NMS: {len(keep_indices)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Visualize NMS\n",
        "\n",
        "def visualize_nms(boxes, scores, keep_indices):\n",
        "    \"\"\"Visualize before and after NMS.\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    \n",
        "    colors = plt.cm.tab10.colors\n",
        "    \n",
        "    # Before NMS\n",
        "    for i, (box, score) in enumerate(zip(boxes, scores)):\n",
        "        rect = patches.Rectangle(\n",
        "            (box[0], box[1]), box[2]-box[0], box[3]-box[1],\n",
        "            linewidth=2, edgecolor=colors[i], facecolor=colors[i], alpha=0.3,\n",
        "            label=f'Box {i}: {score:.2f}'\n",
        "        )\n",
        "        axes[0].add_patch(rect)\n",
        "    \n",
        "    axes[0].set_xlim(0, 500)\n",
        "    axes[0].set_ylim(500, 0)\n",
        "    axes[0].set_title(f'Before NMS ({len(boxes)} boxes)')\n",
        "    axes[0].legend(loc='upper right')\n",
        "    axes[0].set_aspect('equal')\n",
        "    \n",
        "    # After NMS\n",
        "    for i in keep_indices:\n",
        "        box = boxes[i]\n",
        "        score = scores[i]\n",
        "        rect = patches.Rectangle(\n",
        "            (box[0], box[1]), box[2]-box[0], box[3]-box[1],\n",
        "            linewidth=3, edgecolor=colors[i], facecolor=colors[i], alpha=0.4,\n",
        "            label=f'Box {i}: {score:.2f}'\n",
        "        )\n",
        "        axes[1].add_patch(rect)\n",
        "    \n",
        "    axes[1].set_xlim(0, 500)\n",
        "    axes[1].set_ylim(500, 0)\n",
        "    axes[1].set_title(f'After NMS ({len(keep_indices)} boxes)')\n",
        "    axes[1].legend(loc='upper right')\n",
        "    axes[1].set_aspect('equal')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_nms(boxes, scores, keep_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: NMS Threshold Effect\n",
        "\n",
        "# More overlapping boxes for demonstration\n",
        "boxes = [\n",
        "    (100, 100, 200, 200),\n",
        "    (110, 110, 210, 210),\n",
        "    (120, 120, 220, 220),\n",
        "    (130, 130, 230, 230),\n",
        "    (300, 100, 400, 200),\n",
        "    (305, 105, 405, 205),\n",
        "]\n",
        "scores = [0.95, 0.90, 0.85, 0.80, 0.75, 0.70]\n",
        "\n",
        "thresholds = [0.3, 0.5, 0.7, 0.9]\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "\n",
        "for ax, thresh in zip(axes, thresholds):\n",
        "    keep = nms(boxes, scores, iou_threshold=thresh)\n",
        "    \n",
        "    colors = plt.cm.tab10.colors\n",
        "    for i in keep:\n",
        "        box = boxes[i]\n",
        "        rect = patches.Rectangle(\n",
        "            (box[0], box[1]), box[2]-box[0], box[3]-box[1],\n",
        "            linewidth=2, edgecolor=colors[i], facecolor=colors[i], alpha=0.4\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "    \n",
        "    ax.set_xlim(50, 450)\n",
        "    ax.set_ylim(250, 50)\n",
        "    ax.set_title(f'IoU thresh = {thresh}\\n({len(keep)} boxes kept)')\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "plt.suptitle('Effect of NMS IoU Threshold', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Lower threshold = More aggressive removal\")\n",
        "print(\"Higher threshold = Keep more overlapping boxes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1.1\n",
        "\n",
        "Implement Class-Aware NMS: Only suppress boxes if they have the same class.\n",
        "\n",
        "Hint: Group boxes by class first, then apply NMS to each group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "def class_aware_nms(boxes, scores, classes, iou_threshold=0.5):\n",
        "    \"\"\"\n",
        "    NMS that only suppresses boxes of the same class.\n",
        "    \n",
        "    Args:\n",
        "        boxes: List of boxes\n",
        "        scores: List of confidence scores\n",
        "        classes: List of class IDs\n",
        "        iou_threshold: IoU threshold\n",
        "    \n",
        "    Returns:\n",
        "        List of indices to keep\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "# Test\n",
        "# boxes = [(100, 100, 200, 200), (110, 110, 210, 210), (100, 100, 200, 200)]\n",
        "# scores = [0.9, 0.8, 0.85]\n",
        "# classes = [0, 0, 1]  # First two are same class, third is different\n",
        "# Expected: Keep 0 and 2 (or 1 and 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 2: Custom Dataset Preparation\n",
        "\n",
        "## YOLO Dataset Format\n",
        "\n",
        "YOLO expects data in a specific format:\n",
        "\n",
        "```\n",
        "dataset/\n",
        "â”œâ”€â”€ images/\n",
        "â”‚   â”œâ”€â”€ train/\n",
        "â”‚   â”‚   â”œâ”€â”€ img001.jpg\n",
        "â”‚   â”‚   â””â”€â”€ img002.jpg\n",
        "â”‚   â””â”€â”€ val/\n",
        "â”‚       â”œâ”€â”€ img003.jpg\n",
        "â”‚       â””â”€â”€ img004.jpg\n",
        "â”œâ”€â”€ labels/\n",
        "â”‚   â”œâ”€â”€ train/\n",
        "â”‚   â”‚   â”œâ”€â”€ img001.txt\n",
        "â”‚   â”‚   â””â”€â”€ img002.txt\n",
        "â”‚   â””â”€â”€ val/\n",
        "â”‚       â”œâ”€â”€ img003.txt\n",
        "â”‚       â””â”€â”€ img004.txt\n",
        "â””â”€â”€ data.yaml\n",
        "```\n",
        "\n",
        "**Label format (one line per object):**\n",
        "```\n",
        "class_id x_center y_center width height\n",
        "```\n",
        "\n",
        "All values are normalized (0-1)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Convert Coordinates to YOLO Format\n",
        "\n",
        "def xyxy_to_yolo(box, img_width, img_height):\n",
        "    \"\"\"\n",
        "    Convert xyxy box to YOLO format (normalized cxcywh).\n",
        "    \n",
        "    Args:\n",
        "        box: (x1, y1, x2, y2) in pixels\n",
        "        img_width, img_height: Image dimensions\n",
        "    \n",
        "    Returns:\n",
        "        (x_center, y_center, width, height) normalized 0-1\n",
        "    \"\"\"\n",
        "    x1, y1, x2, y2 = box\n",
        "    \n",
        "    # Calculate center and size\n",
        "    x_center = (x1 + x2) / 2 / img_width\n",
        "    y_center = (y1 + y2) / 2 / img_height\n",
        "    width = (x2 - x1) / img_width\n",
        "    height = (y2 - y1) / img_height\n",
        "    \n",
        "    return (x_center, y_center, width, height)\n",
        "\n",
        "def yolo_to_xyxy(yolo_box, img_width, img_height):\n",
        "    \"\"\"\n",
        "    Convert YOLO format back to xyxy (pixels).\n",
        "    \"\"\"\n",
        "    x_center, y_center, width, height = yolo_box\n",
        "    \n",
        "    x1 = (x_center - width/2) * img_width\n",
        "    y1 = (y_center - height/2) * img_height\n",
        "    x2 = (x_center + width/2) * img_width\n",
        "    y2 = (y_center + height/2) * img_height\n",
        "    \n",
        "    return (x1, y1, x2, y2)\n",
        "\n",
        "# Example\n",
        "img_w, img_h = 640, 480\n",
        "box_xyxy = (100, 50, 300, 200)\n",
        "\n",
        "yolo_format = xyxy_to_yolo(box_xyxy, img_w, img_h)\n",
        "print(f\"Original (xyxy): {box_xyxy}\")\n",
        "print(f\"YOLO format: ({yolo_format[0]:.4f}, {yolo_format[1]:.4f}, {yolo_format[2]:.4f}, {yolo_format[3]:.4f})\")\n",
        "\n",
        "# Convert back\n",
        "back_to_xyxy = yolo_to_xyxy(yolo_format, img_w, img_h)\n",
        "print(f\"Back to xyxy: ({back_to_xyxy[0]:.0f}, {back_to_xyxy[1]:.0f}, {back_to_xyxy[2]:.0f}, {back_to_xyxy[3]:.0f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Create a YOLO Label File\n",
        "\n",
        "def create_yolo_label(annotations, img_width, img_height):\n",
        "    \"\"\"\n",
        "    Create YOLO label file content.\n",
        "    \n",
        "    Args:\n",
        "        annotations: List of (class_id, x1, y1, x2, y2)\n",
        "        img_width, img_height: Image dimensions\n",
        "    \n",
        "    Returns:\n",
        "        String content for .txt label file\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    for ann in annotations:\n",
        "        class_id = ann[0]\n",
        "        box = ann[1:5]\n",
        "        yolo_box = xyxy_to_yolo(box, img_width, img_height)\n",
        "        \n",
        "        line = f\"{class_id} {yolo_box[0]:.6f} {yolo_box[1]:.6f} {yolo_box[2]:.6f} {yolo_box[3]:.6f}\"\n",
        "        lines.append(line)\n",
        "    \n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# Example annotations: [(class_id, x1, y1, x2, y2), ...]\n",
        "annotations = [\n",
        "    (0, 100, 50, 300, 200),   # Class 0: dog\n",
        "    (1, 350, 100, 500, 300),  # Class 1: cat\n",
        "    (0, 50, 250, 150, 400),   # Class 0: another dog\n",
        "]\n",
        "\n",
        "label_content = create_yolo_label(annotations, 640, 480)\n",
        "print(\"YOLO label file content:\")\n",
        "print(label_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Create data.yaml Configuration\n",
        "\n",
        "def create_data_yaml(train_path, val_path, class_names):\n",
        "    \"\"\"\n",
        "    Create YOLO data.yaml configuration.\n",
        "    \"\"\"\n",
        "    yaml_content = f\"\"\"# YOLO Dataset Configuration\n",
        "path: .  # Dataset root directory\n",
        "train: {train_path}  # Training images\n",
        "val: {val_path}  # Validation images\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "\"\"\"\n",
        "    for i, name in enumerate(class_names):\n",
        "        yaml_content += f\"  {i}: {name}\\n\"\n",
        "    \n",
        "    return yaml_content\n",
        "\n",
        "# Example\n",
        "class_names = ['dog', 'cat', 'bird']\n",
        "yaml_content = create_data_yaml('images/train', 'images/val', class_names)\n",
        "\n",
        "print(\"data.yaml content:\")\n",
        "print(yaml_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Roboflow for Easy Labeling\n",
        "\n",
        "[Roboflow](https://roboflow.com/) is a free tool for:\n",
        "- Labeling images with bounding boxes\n",
        "- Augmenting your dataset\n",
        "- Exporting in YOLO format\n",
        "\n",
        "For this lab, we'll use a pre-made dataset from Roboflow Universe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Download Sample Dataset from Roboflow\n",
        "\n",
        "# We'll use a small playing cards dataset\n",
        "# You can browse more at: https://universe.roboflow.com/\n",
        "\n",
        "from roboflow import Roboflow\n",
        "\n",
        "# Note: For the lab, we'll create a minimal synthetic dataset\n",
        "# In practice, you'd download from Roboflow like this:\n",
        "# rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
        "# project = rf.workspace(\"workspace\").project(\"project-name\")\n",
        "# dataset = project.version(1).download(\"yolov8\")\n",
        "\n",
        "print(\"For a real project, sign up at roboflow.com and download a dataset!\")\n",
        "print(\"\\nWe'll create a synthetic dataset for demonstration.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Create Synthetic Dataset for Demo\n",
        "\n",
        "import shutil\n",
        "\n",
        "# Create directory structure\n",
        "dataset_dir = \"demo_dataset\"\n",
        "os.makedirs(f\"{dataset_dir}/images/train\", exist_ok=True)\n",
        "os.makedirs(f\"{dataset_dir}/images/val\", exist_ok=True)\n",
        "os.makedirs(f\"{dataset_dir}/labels/train\", exist_ok=True)\n",
        "os.makedirs(f\"{dataset_dir}/labels/val\", exist_ok=True)\n",
        "\n",
        "# Create synthetic images with colored rectangles (simulating objects)\n",
        "np.random.seed(42)\n",
        "\n",
        "class_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]  # RGB\n",
        "class_names = ['red_square', 'green_square', 'blue_square']\n",
        "\n",
        "def create_synthetic_image(img_size=(416, 416), num_objects=3):\n",
        "    \"\"\"Create a synthetic image with colored squares.\"\"\"\n",
        "    img = np.ones((img_size[1], img_size[0], 3), dtype=np.uint8) * 200  # Gray background\n",
        "    annotations = []\n",
        "    \n",
        "    for _ in range(num_objects):\n",
        "        # Random class\n",
        "        class_id = np.random.randint(0, 3)\n",
        "        color = class_colors[class_id]\n",
        "        \n",
        "        # Random position and size\n",
        "        size = np.random.randint(30, 80)\n",
        "        x1 = np.random.randint(0, img_size[0] - size)\n",
        "        y1 = np.random.randint(0, img_size[1] - size)\n",
        "        x2 = x1 + size\n",
        "        y2 = y1 + size\n",
        "        \n",
        "        # Draw rectangle\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), color, -1)\n",
        "        \n",
        "        annotations.append((class_id, x1, y1, x2, y2))\n",
        "    \n",
        "    return img, annotations\n",
        "\n",
        "# Create training images\n",
        "for i in range(20):\n",
        "    img, annotations = create_synthetic_image(num_objects=np.random.randint(1, 5))\n",
        "    \n",
        "    # Save image\n",
        "    img_path = f\"{dataset_dir}/images/train/img_{i:03d}.jpg\"\n",
        "    cv2.imwrite(img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "    \n",
        "    # Save label\n",
        "    label_content = create_yolo_label(annotations, 416, 416)\n",
        "    label_path = f\"{dataset_dir}/labels/train/img_{i:03d}.txt\"\n",
        "    with open(label_path, 'w') as f:\n",
        "        f.write(label_content)\n",
        "\n",
        "# Create validation images\n",
        "for i in range(5):\n",
        "    img, annotations = create_synthetic_image(num_objects=np.random.randint(1, 5))\n",
        "    \n",
        "    img_path = f\"{dataset_dir}/images/val/img_{i:03d}.jpg\"\n",
        "    cv2.imwrite(img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "    \n",
        "    label_content = create_yolo_label(annotations, 416, 416)\n",
        "    label_path = f\"{dataset_dir}/labels/val/img_{i:03d}.txt\"\n",
        "    with open(label_path, 'w') as f:\n",
        "        f.write(label_content)\n",
        "\n",
        "# Create data.yaml\n",
        "yaml_content = f\"\"\"path: {os.path.abspath(dataset_dir)}\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "names:\n",
        "  0: red_square\n",
        "  1: green_square\n",
        "  2: blue_square\n",
        "\"\"\"\n",
        "\n",
        "with open(f\"{dataset_dir}/data.yaml\", 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"Created synthetic dataset:\")\n",
        "print(f\"  Training images: 20\")\n",
        "print(f\"  Validation images: 5\")\n",
        "print(f\"  Classes: {class_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Visualize Dataset\n",
        "\n",
        "# Load a sample image and its labels\n",
        "sample_img = cv2.imread(f\"{dataset_dir}/images/train/img_000.jpg\")\n",
        "sample_img = cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "with open(f\"{dataset_dir}/labels/train/img_000.txt\", 'r') as f:\n",
        "    labels = f.read().strip().split('\\n')\n",
        "\n",
        "# Draw boxes\n",
        "h, w = sample_img.shape[:2]\n",
        "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "\n",
        "for label in labels:\n",
        "    parts = label.split()\n",
        "    class_id = int(parts[0])\n",
        "    yolo_box = [float(x) for x in parts[1:]]\n",
        "    \n",
        "    # Convert to xyxy\n",
        "    x1, y1, x2, y2 = yolo_to_xyxy(yolo_box, w, h)\n",
        "    \n",
        "    cv2.rectangle(sample_img, (int(x1), int(y1)), (int(x2), int(y2)), colors[class_id], 2)\n",
        "    cv2.putText(sample_img, class_names[class_id], (int(x1), int(y1)-5), \n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[class_id], 2)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(sample_img)\n",
        "plt.title('Sample Training Image with Annotations')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2.1\n",
        "\n",
        "Write a function that validates a YOLO label file:\n",
        "1. Check that all coordinates are between 0 and 1\n",
        "2. Check that class IDs are valid\n",
        "3. Check that boxes have positive width and height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "def validate_yolo_label(label_path, num_classes):\n",
        "    \"\"\"\n",
        "    Validate a YOLO label file.\n",
        "    \n",
        "    Returns:\n",
        "        (is_valid, errors): Tuple of boolean and list of error messages\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 3: Fine-tuning YOLO\n",
        "\n",
        "## Why Fine-tune?\n",
        "\n",
        "Pre-trained YOLO knows 80 common objects (COCO dataset).\n",
        "\n",
        "But what if you want to detect:\n",
        "- Specific product types\n",
        "- Custom machinery parts\n",
        "- Rare objects not in COCO\n",
        "\n",
        "**Fine-tuning = Start from pre-trained weights, train on YOUR data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Fine-tune YOLO on Custom Data\n",
        "\n",
        "# Load pre-trained model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Fine-tune on our dataset\n",
        "# Note: This will take a few minutes even on GPU\n",
        "results = model.train(\n",
        "    data=f\"{dataset_dir}/data.yaml\",\n",
        "    epochs=10,        # More epochs for better results\n",
        "    imgsz=416,        # Image size\n",
        "    batch=8,          # Batch size (reduce if OOM)\n",
        "    patience=5,       # Early stopping\n",
        "    verbose=True,\n",
        "    plots=True,       # Generate training plots\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Evaluate Fine-tuned Model\n",
        "\n",
        "# Load the best model\n",
        "best_model = YOLO('runs/detect/train/weights/best.pt')\n",
        "\n",
        "# Validate on validation set\n",
        "metrics = best_model.val()\n",
        "\n",
        "print(\"\\nValidation Metrics:\")\n",
        "print(f\"  mAP50: {metrics.box.map50:.4f}\")\n",
        "print(f\"  mAP50-95: {metrics.box.map:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Test on New Image\n",
        "\n",
        "# Create a test image\n",
        "test_img, test_annotations = create_synthetic_image(num_objects=4)\n",
        "\n",
        "# Run detection\n",
        "results = best_model(test_img)\n",
        "result = results[0]\n",
        "\n",
        "# Visualize\n",
        "annotated = result.plot()\n",
        "annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(annotated)\n",
        "plt.title('Detection with Fine-tuned Model')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 4: Evaluation Metrics\n",
        "\n",
        "## Precision and Recall\n",
        "\n",
        "```\n",
        "PRECISION: Of all detections, how many are correct?\n",
        "           Precision = TP / (TP + FP)\n",
        "\n",
        "RECALL: Of all ground truth objects, how many did we find?\n",
        "        Recall = TP / (TP + FN)\n",
        "\n",
        "Where:\n",
        "  TP (True Positive)  = Correct detection (IoU >= 0.5)\n",
        "  FP (False Positive) = Wrong detection (no matching GT)\n",
        "  FN (False Negative) = Missed object (GT with no detection)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Calculate Precision and Recall\n",
        "\n",
        "def calculate_metrics(pred_boxes, gt_boxes, iou_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate precision and recall.\n",
        "    \n",
        "    Args:\n",
        "        pred_boxes: List of predicted boxes\n",
        "        gt_boxes: List of ground truth boxes\n",
        "        iou_threshold: IoU threshold for correct detection\n",
        "    \n",
        "    Returns:\n",
        "        (precision, recall, tp, fp, fn)\n",
        "    \"\"\"\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    matched_gt = set()\n",
        "    \n",
        "    for pred in pred_boxes:\n",
        "        best_iou = 0\n",
        "        best_gt_idx = -1\n",
        "        \n",
        "        for gt_idx, gt in enumerate(gt_boxes):\n",
        "            if gt_idx in matched_gt:\n",
        "                continue\n",
        "            iou = calculate_iou(pred, gt)\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_gt_idx = gt_idx\n",
        "        \n",
        "        if best_iou >= iou_threshold:\n",
        "            tp += 1\n",
        "            matched_gt.add(best_gt_idx)\n",
        "        else:\n",
        "            fp += 1\n",
        "    \n",
        "    fn = len(gt_boxes) - len(matched_gt)\n",
        "    \n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    \n",
        "    return precision, recall, tp, fp, fn\n",
        "\n",
        "# Example\n",
        "predictions = [(100, 100, 200, 200), (300, 300, 400, 400), (50, 50, 100, 100)]\n",
        "ground_truths = [(105, 105, 205, 205), (310, 310, 410, 410)]  # Only 2 objects\n",
        "\n",
        "prec, rec, tp, fp, fn = calculate_metrics(predictions, ground_truths)\n",
        "\n",
        "print(\"Metrics:\")\n",
        "print(f\"  True Positives: {tp}\")\n",
        "print(f\"  False Positives: {fp}\")\n",
        "print(f\"  False Negatives: {fn}\")\n",
        "print(f\"  Precision: {prec:.2%}\")\n",
        "print(f\"  Recall: {rec:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mean Average Precision (mAP)\n",
        "\n",
        "mAP is the standard metric for object detection.\n",
        "\n",
        "```\n",
        "mAP CALCULATION:\n",
        "\n",
        "1. For each class:\n",
        "   - Sort detections by confidence\n",
        "   - Calculate precision/recall at each threshold\n",
        "   - Compute Average Precision (area under P-R curve)\n",
        "\n",
        "2. Average across all classes = mAP\n",
        "\n",
        "mAP@50: IoU threshold = 0.5\n",
        "mAP@50:95: Average mAP at IoU from 0.5 to 0.95 (step 0.05)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Precision-Recall Curve\n",
        "\n",
        "def precision_recall_curve(predictions, ground_truths, iou_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate precision-recall curve.\n",
        "    \n",
        "    Args:\n",
        "        predictions: List of (box, confidence)\n",
        "        ground_truths: List of boxes\n",
        "    \n",
        "    Returns:\n",
        "        precisions, recalls\n",
        "    \"\"\"\n",
        "    # Sort by confidence\n",
        "    sorted_preds = sorted(predictions, key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    \n",
        "    for i in range(1, len(sorted_preds) + 1):\n",
        "        boxes = [p[0] for p in sorted_preds[:i]]\n",
        "        prec, rec, _, _, _ = calculate_metrics(boxes, ground_truths, iou_threshold)\n",
        "        precisions.append(prec)\n",
        "        recalls.append(rec)\n",
        "    \n",
        "    return precisions, recalls\n",
        "\n",
        "# Example with varying confidence\n",
        "predictions_with_conf = [\n",
        "    ((100, 100, 200, 200), 0.95),  # Good detection\n",
        "    ((105, 105, 205, 205), 0.85),  # Duplicate of first\n",
        "    ((300, 300, 400, 400), 0.75),  # Good detection\n",
        "    ((500, 500, 600, 600), 0.65),  # False positive\n",
        "    ((50, 50, 100, 100), 0.55),    # False positive\n",
        "]\n",
        "\n",
        "ground_truths = [(100, 100, 200, 200), (300, 300, 400, 400)]\n",
        "\n",
        "precisions, recalls = precision_recall_curve(predictions_with_conf, ground_truths)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recalls, precisions, 'b-o', linewidth=2, markersize=8)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.xlim([0, 1.05])\n",
        "plt.ylim([0, 1.05])\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate AP (area under curve, simplified)\n",
        "ap = np.trapz(precisions, recalls)\n",
        "print(f\"Average Precision (AP): {ap:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3.1\n",
        "\n",
        "Given these detection results, calculate:\n",
        "1. Precision and Recall at confidence threshold 0.5\n",
        "2. mAP (using simplified trapezoid integration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# Given data\n",
        "detections = [\n",
        "    ((50, 50, 150, 150), 0.9, 'dog'),\n",
        "    ((200, 200, 300, 300), 0.8, 'cat'),\n",
        "    ((55, 55, 155, 155), 0.7, 'dog'),  # Duplicate\n",
        "    ((400, 400, 500, 500), 0.6, 'dog'),  # False positive\n",
        "    ((210, 210, 310, 310), 0.5, 'cat'),  # Duplicate\n",
        "    ((600, 600, 700, 700), 0.4, 'bird'),  # False positive\n",
        "]\n",
        "\n",
        "ground_truth = [\n",
        "    ((50, 50, 150, 150), 'dog'),\n",
        "    ((200, 200, 300, 300), 'cat'),\n",
        "    ((350, 350, 450, 450), 'dog'),  # Missed\n",
        "]\n",
        "\n",
        "# Calculate metrics\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Challenge Problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Challenge 1: Soft-NMS\n",
        "\n",
        "Instead of completely removing overlapping boxes, Soft-NMS reduces their confidence:\n",
        "\n",
        "```\n",
        "For each box with IoU > threshold with best box:\n",
        "  score = score * (1 - IoU)  # Linear decay\n",
        "  # or\n",
        "  score = score * exp(-IoU^2 / sigma)  # Gaussian decay\n",
        "```\n",
        "\n",
        "Implement Soft-NMS and compare with standard NMS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "def soft_nms(boxes, scores, sigma=0.5, threshold=0.001):\n",
        "    \"\"\"\n",
        "    Soft Non-Maximum Suppression with Gaussian decay.\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Challenge 2: Real-time Detection\n",
        "\n",
        "Create a script that runs YOLO on webcam feed in real-time.\n",
        "Display FPS (frames per second) on the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# Note: This won't work in Colab, but will work locally\n",
        "\n",
        "def webcam_detection():\n",
        "    \"\"\"\n",
        "    Run YOLO detection on webcam feed.\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Challenge 3: Multi-Object Tracking\n",
        "\n",
        "Extend detection to tracking: assign consistent IDs to objects across frames.\n",
        "\n",
        "Hint: Use IoU between frames to associate detections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "def simple_tracker(prev_detections, curr_detections, iou_threshold=0.3):\n",
        "    \"\"\"\n",
        "    Simple IoU-based tracker.\n",
        "    \n",
        "    Returns:\n",
        "        List of (detection, track_id) pairs\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Summary\n",
        "\n",
        "## What We Learned\n",
        "\n",
        "| Concept | Description |\n",
        "|---------|-------------|\n",
        "| **NMS** | Remove duplicate detections by IoU |\n",
        "| **YOLO Format** | Normalized (cx, cy, w, h) labels |\n",
        "| **Fine-tuning** | Train pre-trained model on custom data |\n",
        "| **Precision** | TP / (TP + FP) - accuracy of detections |\n",
        "| **Recall** | TP / (TP + FN) - completeness of detections |\n",
        "| **mAP** | Average precision across classes and IoU thresholds |\n",
        "\n",
        "## Key Code Patterns\n",
        "\n",
        "```python\n",
        "# Fine-tune YOLO\n",
        "model = YOLO('yolov8n.pt')\n",
        "model.train(\n",
        "    data='data.yaml',\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=16\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "metrics = model.val()\n",
        "print(f\"mAP50: {metrics.box.map50}\")\n",
        "\n",
        "# NMS\n",
        "keep_indices = nms(boxes, scores, iou_threshold=0.5)\n",
        "```\n",
        "\n",
        "## Congratulations!\n",
        "\n",
        "You've completed the Object Detection labs! You now understand:\n",
        "- How YOLO works and how to use it\n",
        "- How to prepare custom datasets\n",
        "- How to fine-tune models for your specific use case\n",
        "- How to evaluate detection performance"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
