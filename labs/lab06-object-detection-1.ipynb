{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 6: Object Detection - Part 1\n",
        "## Bounding Boxes, YOLO, and Visualization\n",
        "\n",
        "**Duration**: ~3 hours\n",
        "\n",
        "### Learning Objectives\n",
        "By the end of this lab, you will be able to:\n",
        "1. Understand bounding box representations\n",
        "2. Use a pre-trained YOLO model for object detection\n",
        "3. Visualize detections with bounding boxes and labels\n",
        "4. Calculate Intersection over Union (IoU)\n",
        "\n",
        "### Prerequisites\n",
        "- Completed Labs 1-3 (Python, NumPy, basic ML)\n",
        "- Basic understanding of images as arrays\n",
        "\n",
        "### What is Object Detection?\n",
        "\n",
        "```\n",
        "CLASSIFICATION vs DETECTION:\n",
        "\n",
        "Classification:                Detection:\n",
        "\"What is in the image?\"        \"What is in the image AND where?\"\n",
        "\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚               â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”      â”‚\n",
        "â”‚    ðŸ•         â”‚              â”‚  â”‚ ðŸ•  â”‚      â”‚\n",
        "â”‚               â”‚              â”‚  â”‚ dog â”‚      â”‚\n",
        "â”‚               â”‚              â”‚  â””â”€â”€â”€â”€â”€â”˜      â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚    â”Œâ”€â”€â”€â”€â”     â”‚\n",
        "                               â”‚    â”‚ ðŸˆ â”‚     â”‚\n",
        "Output: \"dog\"                  â”‚    â”‚cat â”‚     â”‚\n",
        "                               â”‚    â””â”€â”€â”€â”€â”˜     â”‚\n",
        "                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                               \n",
        "                               Output: [(dog, box1), (cat, box2)]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# !pip install ultralytics supervision opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (12, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 1: Understanding Bounding Boxes\n",
        "\n",
        "## What is a Bounding Box?\n",
        "\n",
        "A bounding box is a rectangle that surrounds an object in an image.\n",
        "\n",
        "```\n",
        "IMAGE COORDINATES:\n",
        "\n",
        "(0,0) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º x\n",
        "  â”‚\n",
        "  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "  â”‚    â”‚             â”‚\n",
        "  â”‚    â”‚   Object    â”‚ height (h)\n",
        "  â”‚    â”‚             â”‚\n",
        "  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "  â”‚         width (w)\n",
        "  â”‚\n",
        "  â–¼\n",
        "  y\n",
        "```\n",
        "\n",
        "## Different Box Formats\n",
        "\n",
        "| Format | Description | Example |\n",
        "|--------|-------------|----------|\n",
        "| **xyxy** | (x1, y1, x2, y2) - corners | (100, 50, 200, 150) |\n",
        "| **xywh** | (x, y, width, height) - top-left + size | (100, 50, 100, 100) |\n",
        "| **cxcywh** | (cx, cy, width, height) - center + size | (150, 100, 100, 100) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Box Format Conversions\n",
        "\n",
        "def xyxy_to_xywh(box):\n",
        "    \"\"\"Convert (x1, y1, x2, y2) to (x, y, w, h)\"\"\"\n",
        "    x1, y1, x2, y2 = box\n",
        "    return (x1, y1, x2 - x1, y2 - y1)\n",
        "\n",
        "def xywh_to_xyxy(box):\n",
        "    \"\"\"Convert (x, y, w, h) to (x1, y1, x2, y2)\"\"\"\n",
        "    x, y, w, h = box\n",
        "    return (x, y, x + w, y + h)\n",
        "\n",
        "def xyxy_to_cxcywh(box):\n",
        "    \"\"\"Convert (x1, y1, x2, y2) to (cx, cy, w, h)\"\"\"\n",
        "    x1, y1, x2, y2 = box\n",
        "    w = x2 - x1\n",
        "    h = y2 - y1\n",
        "    cx = x1 + w / 2\n",
        "    cy = y1 + h / 2\n",
        "    return (cx, cy, w, h)\n",
        "\n",
        "# Example\n",
        "box_xyxy = (100, 50, 200, 150)\n",
        "print(f\"xyxy format: {box_xyxy}\")\n",
        "print(f\"xywh format: {xyxy_to_xywh(box_xyxy)}\")\n",
        "print(f\"cxcywh format: {xyxy_to_cxcywh(box_xyxy)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Visualize Box Formats\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Create a simple image\n",
        "img = np.ones((200, 300, 3)) * 0.9  # Light gray background\n",
        "\n",
        "box = (100, 50, 200, 150)  # xyxy format\n",
        "x1, y1, x2, y2 = box\n",
        "\n",
        "# xyxy format\n",
        "axes[0].imshow(img)\n",
        "rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, \n",
        "                          linewidth=3, edgecolor='red', facecolor='none')\n",
        "axes[0].add_patch(rect)\n",
        "axes[0].plot(x1, y1, 'ro', markersize=10)\n",
        "axes[0].plot(x2, y2, 'bo', markersize=10)\n",
        "axes[0].annotate(f'(x1={x1}, y1={y1})', (x1, y1-10), color='red')\n",
        "axes[0].annotate(f'(x2={x2}, y2={y2})', (x2, y2+15), color='blue')\n",
        "axes[0].set_title('xyxy: Two Corners')\n",
        "\n",
        "# xywh format\n",
        "x, y, w, h = xyxy_to_xywh(box)\n",
        "axes[1].imshow(img)\n",
        "rect = patches.Rectangle((x, y), w, h, \n",
        "                          linewidth=3, edgecolor='green', facecolor='none')\n",
        "axes[1].add_patch(rect)\n",
        "axes[1].plot(x, y, 'go', markersize=10)\n",
        "axes[1].annotate(f'(x={x}, y={y})', (x, y-10), color='green')\n",
        "axes[1].annotate(f'w={w}', (x + w/2, y2+15), color='green', ha='center')\n",
        "axes[1].annotate(f'h={h}', (x2+10, y + h/2), color='green', va='center')\n",
        "axes[1].set_title('xywh: Top-Left + Size')\n",
        "\n",
        "# cxcywh format\n",
        "cx, cy, w, h = xyxy_to_cxcywh(box)\n",
        "axes[2].imshow(img)\n",
        "rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, \n",
        "                          linewidth=3, edgecolor='purple', facecolor='none')\n",
        "axes[2].add_patch(rect)\n",
        "axes[2].plot(cx, cy, 'mo', markersize=10)\n",
        "axes[2].annotate(f'Center ({cx}, {cy})', (cx+5, cy-5), color='purple')\n",
        "axes[2].set_title('cxcywh: Center + Size')\n",
        "\n",
        "for ax in axes:\n",
        "    ax.set_xlim(0, 300)\n",
        "    ax.set_ylim(200, 0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Drawing Boxes on Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Draw Bounding Box with OpenCV\n",
        "\n",
        "def draw_box(image, box, label, color=(0, 255, 0), thickness=2):\n",
        "    \"\"\"\n",
        "    Draw a bounding box with label on an image.\n",
        "    \n",
        "    Args:\n",
        "        image: numpy array (H, W, 3) in RGB\n",
        "        box: (x1, y1, x2, y2) format\n",
        "        label: text to display\n",
        "        color: RGB tuple\n",
        "        thickness: line thickness\n",
        "    \"\"\"\n",
        "    img = image.copy()\n",
        "    x1, y1, x2, y2 = [int(v) for v in box]\n",
        "    \n",
        "    # Draw rectangle\n",
        "    cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
        "    \n",
        "    # Draw label background\n",
        "    (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
        "    cv2.rectangle(img, (x1, y1 - text_height - 10), (x1 + text_width + 5, y1), color, -1)\n",
        "    \n",
        "    # Draw label text\n",
        "    cv2.putText(img, label, (x1 + 2, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
        "    \n",
        "    return img\n",
        "\n",
        "# Create a sample image\n",
        "sample_img = np.ones((400, 600, 3), dtype=np.uint8) * 200\n",
        "\n",
        "# Draw some boxes\n",
        "sample_img = draw_box(sample_img, (50, 50, 200, 200), \"Dog: 0.95\", color=(0, 255, 0))\n",
        "sample_img = draw_box(sample_img, (300, 100, 500, 350), \"Cat: 0.87\", color=(255, 0, 0))\n",
        "sample_img = draw_box(sample_img, (150, 250, 350, 380), \"Bird: 0.72\", color=(0, 0, 255))\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(sample_img)\n",
        "plt.title('Bounding Boxes with Labels')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1.1\n",
        "\n",
        "Write a function `cxcywh_to_xyxy(box)` that converts from center format to corner format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "def cxcywh_to_xyxy(box):\n",
        "    \"\"\"Convert (cx, cy, w, h) to (x1, y1, x2, y2)\"\"\"\n",
        "    # Hint: cx = x1 + w/2, so x1 = cx - w/2\n",
        "    pass\n",
        "\n",
        "# Test\n",
        "# box_cxcywh = (150, 100, 100, 100)\n",
        "# Expected output: (100, 50, 200, 150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 2: Using Pre-trained YOLO\n",
        "\n",
        "## What is YOLO?\n",
        "\n",
        "**YOLO = You Only Look Once**\n",
        "\n",
        "Unlike older methods that look at many image regions, YOLO processes the entire image in one pass.\n",
        "\n",
        "```\n",
        "OLDER METHODS:              YOLO:\n",
        "\n",
        "Look at 1000s of regions    Look at image ONCE\n",
        "â”Œâ”€â”¬â”€â”¬â”€â”¬â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”œâ”€â”¼â”€â”¼â”€â”¼â”€â”¤  â†’ Slow           â”‚           â”‚ â†’ Fast!\n",
        "â”œâ”€â”¼â”€â”¼â”€â”¼â”€â”¤                   â”‚   Grid    â”‚\n",
        "â”œâ”€â”¼â”€â”¼â”€â”¼â”€â”¤                   â”‚           â”‚\n",
        "â””â”€â”´â”€â”´â”€â”´â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "We'll use **YOLOv8** from Ultralytics - the latest and easiest to use!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load pre-trained model (downloads automatically)\n",
        "model = YOLO('yolov8n.pt')  # 'n' = nano (smallest, fastest)\n",
        "\n",
        "print(\"Model loaded!\")\n",
        "print(f\"Model type: YOLOv8 Nano\")\n",
        "print(f\"Number of classes: {len(model.names)}\")\n",
        "print(f\"\\nFirst 20 classes: {list(model.names.values())[:20]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Download a Sample Image\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "# Download a sample image\n",
        "url = \"https://ultralytics.com/images/bus.jpg\"\n",
        "image_path = \"bus.jpg\"\n",
        "\n",
        "if not os.path.exists(image_path):\n",
        "    urllib.request.urlretrieve(url, image_path)\n",
        "    print(f\"Downloaded {image_path}\")\n",
        "\n",
        "# Display image\n",
        "img = Image.open(image_path)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(img)\n",
        "plt.title('Sample Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Image size: {img.size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Run Detection\n",
        "\n",
        "# Run inference\n",
        "results = model(image_path)\n",
        "\n",
        "# Get the first result (we only have one image)\n",
        "result = results[0]\n",
        "\n",
        "print(\"Detection Results:\")\n",
        "print(f\"  Number of detections: {len(result.boxes)}\")\n",
        "print(f\"  Inference time: {result.speed['inference']:.1f} ms\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Understanding the Output\n",
        "\n",
        "# Access detection boxes\n",
        "boxes = result.boxes\n",
        "\n",
        "print(\"\\nDetailed Results:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, box in enumerate(boxes):\n",
        "    # Get coordinates (xyxy format)\n",
        "    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "    \n",
        "    # Get confidence\n",
        "    conf = box.conf[0].item()\n",
        "    \n",
        "    # Get class\n",
        "    cls_id = int(box.cls[0].item())\n",
        "    cls_name = model.names[cls_id]\n",
        "    \n",
        "    print(f\"Detection {i+1}:\")\n",
        "    print(f\"  Class: {cls_name}\")\n",
        "    print(f\"  Confidence: {conf:.2%}\")\n",
        "    print(f\"  Box (xyxy): ({x1:.0f}, {y1:.0f}, {x2:.0f}, {y2:.0f})\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Visualize Detections (Built-in)\n",
        "\n",
        "# YOLO has built-in visualization\n",
        "annotated_image = result.plot()\n",
        "\n",
        "# Convert BGR to RGB for matplotlib\n",
        "annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(14, 10))\n",
        "plt.imshow(annotated_image)\n",
        "plt.title('YOLO Detections')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Different Model Sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Compare Model Sizes\n",
        "\n",
        "model_sizes = {\n",
        "    'yolov8n.pt': 'Nano (fastest)',\n",
        "    'yolov8s.pt': 'Small',\n",
        "    'yolov8m.pt': 'Medium',\n",
        "}\n",
        "\n",
        "print(\"Model Size Comparison:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for model_name, description in model_sizes.items():\n",
        "    temp_model = YOLO(model_name)\n",
        "    results = temp_model(image_path, verbose=False)\n",
        "    \n",
        "    inference_time = results[0].speed['inference']\n",
        "    num_detections = len(results[0].boxes)\n",
        "    \n",
        "    print(f\"{description:20s}: {inference_time:6.1f} ms, {num_detections} detections\")\n",
        "\n",
        "print(\"\\nNote: Larger models are more accurate but slower.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2.1\n",
        "\n",
        "Download your own image (or use one from your computer) and run YOLO detection on it.\n",
        "Print all detected objects with their confidence scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# Option 1: Use a URL\n",
        "# your_image_url = \"https://example.com/image.jpg\"\n",
        "\n",
        "# Option 2: Upload an image to Colab\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# Run detection\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 3: Custom Visualization with Supervision\n",
        "\n",
        "The `supervision` library provides beautiful, customizable visualizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "print(f\"Supervision version: {sv.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Supervision Visualization\n",
        "\n",
        "# Get YOLO results\n",
        "results = model(image_path)\n",
        "result = results[0]\n",
        "\n",
        "# Convert to supervision format\n",
        "detections = sv.Detections.from_ultralytics(result)\n",
        "\n",
        "print(f\"Number of detections: {len(detections)}\")\n",
        "print(f\"\\nDetection attributes:\")\n",
        "print(f\"  xyxy: {detections.xyxy.shape}\")\n",
        "print(f\"  confidence: {detections.confidence}\")\n",
        "print(f\"  class_id: {detections.class_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Custom Annotator\n",
        "\n",
        "# Load image\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Create annotators\n",
        "box_annotator = sv.BoxAnnotator(\n",
        "    thickness=2,\n",
        "    color=sv.ColorPalette.DEFAULT\n",
        ")\n",
        "\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    text_scale=0.5,\n",
        "    text_padding=5\n",
        ")\n",
        "\n",
        "# Generate labels\n",
        "labels = [\n",
        "    f\"{model.names[class_id]} {confidence:.2f}\"\n",
        "    for class_id, confidence in zip(detections.class_id, detections.confidence)\n",
        "]\n",
        "\n",
        "# Annotate\n",
        "annotated = box_annotator.annotate(scene=image.copy(), detections=detections)\n",
        "annotated = label_annotator.annotate(scene=annotated, detections=detections, labels=labels)\n",
        "\n",
        "plt.figure(figsize=(14, 10))\n",
        "plt.imshow(annotated)\n",
        "plt.title('Custom Visualization with Supervision')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Filter by Confidence\n",
        "\n",
        "# Only keep high confidence detections\n",
        "high_conf = detections[detections.confidence > 0.5]\n",
        "\n",
        "print(f\"Original detections: {len(detections)}\")\n",
        "print(f\"After filtering (conf > 0.5): {len(high_conf)}\")\n",
        "\n",
        "# Visualize\n",
        "labels = [\n",
        "    f\"{model.names[class_id]} {confidence:.2f}\"\n",
        "    for class_id, confidence in zip(high_conf.class_id, high_conf.confidence)\n",
        "]\n",
        "\n",
        "annotated = box_annotator.annotate(scene=image.copy(), detections=high_conf)\n",
        "annotated = label_annotator.annotate(scene=annotated, detections=high_conf, labels=labels)\n",
        "\n",
        "plt.figure(figsize=(14, 10))\n",
        "plt.imshow(annotated)\n",
        "plt.title('High Confidence Detections Only (> 0.5)')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Filter by Class\n",
        "\n",
        "# Only keep 'person' detections\n",
        "person_class_id = list(model.names.keys())[list(model.names.values()).index('person')]\n",
        "person_detections = detections[detections.class_id == person_class_id]\n",
        "\n",
        "print(f\"Person class ID: {person_class_id}\")\n",
        "print(f\"Number of persons detected: {len(person_detections)}\")\n",
        "\n",
        "# Visualize\n",
        "labels = [f\"person {conf:.2f}\" for conf in person_detections.confidence]\n",
        "\n",
        "person_annotator = sv.BoxAnnotator(thickness=3, color=sv.Color.RED)\n",
        "annotated = person_annotator.annotate(scene=image.copy(), detections=person_detections)\n",
        "annotated = label_annotator.annotate(scene=annotated, detections=person_detections, labels=labels)\n",
        "\n",
        "plt.figure(figsize=(14, 10))\n",
        "plt.imshow(annotated)\n",
        "plt.title('Only Persons')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3.1\n",
        "\n",
        "Create a visualization that:\n",
        "1. Shows only vehicles (car, truck, bus)\n",
        "2. Uses a different color for each vehicle type\n",
        "3. Displays the count of each vehicle type in the title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# Vehicle class IDs (you can find these by printing model.names)\n",
        "# car = 2, truck = 7, bus = 5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 4: Intersection over Union (IoU)\n",
        "\n",
        "## What is IoU?\n",
        "\n",
        "IoU measures how much two boxes overlap.\n",
        "\n",
        "```\n",
        "IoU = Area of Intersection / Area of Union\n",
        "\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚   Box A   â”‚\n",
        "â”‚     â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚     â”‚XXXXXâ”‚       â”‚\n",
        "â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”˜       â”‚\n",
        "      â”‚    Box B    â”‚\n",
        "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "XXX = Intersection\n",
        "\n",
        "IoU = Area(XXX) / Area(A âˆª B)\n",
        "\n",
        "IoU = 0: No overlap\n",
        "IoU = 1: Perfect overlap\n",
        "IoU > 0.5: Usually considered \"good match\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Calculate IoU\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    \"\"\"\n",
        "    Calculate Intersection over Union between two boxes.\n",
        "    \n",
        "    Args:\n",
        "        box1, box2: Boxes in (x1, y1, x2, y2) format\n",
        "    \n",
        "    Returns:\n",
        "        IoU value (0 to 1)\n",
        "    \"\"\"\n",
        "    # Unpack coordinates\n",
        "    x1_1, y1_1, x2_1, y2_1 = box1\n",
        "    x1_2, y1_2, x2_2, y2_2 = box2\n",
        "    \n",
        "    # Calculate intersection coordinates\n",
        "    x1_i = max(x1_1, x1_2)\n",
        "    y1_i = max(y1_1, y1_2)\n",
        "    x2_i = min(x2_1, x2_2)\n",
        "    y2_i = min(y2_1, y2_2)\n",
        "    \n",
        "    # Calculate intersection area\n",
        "    if x2_i < x1_i or y2_i < y1_i:\n",
        "        intersection = 0  # No overlap\n",
        "    else:\n",
        "        intersection = (x2_i - x1_i) * (y2_i - y1_i)\n",
        "    \n",
        "    # Calculate areas of both boxes\n",
        "    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "    \n",
        "    # Calculate union\n",
        "    union = area1 + area2 - intersection\n",
        "    \n",
        "    # Calculate IoU\n",
        "    iou = intersection / union if union > 0 else 0\n",
        "    \n",
        "    return iou\n",
        "\n",
        "# Test cases\n",
        "box_a = (0, 0, 100, 100)\n",
        "box_b = (50, 50, 150, 150)\n",
        "box_c = (200, 200, 300, 300)  # No overlap with A\n",
        "box_d = (0, 0, 100, 100)  # Same as A\n",
        "\n",
        "print(f\"IoU(A, B) = {calculate_iou(box_a, box_b):.4f}\")\n",
        "print(f\"IoU(A, C) = {calculate_iou(box_a, box_c):.4f} (no overlap)\")\n",
        "print(f\"IoU(A, D) = {calculate_iou(box_a, box_d):.4f} (perfect overlap)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: Visualize IoU\n",
        "\n",
        "def visualize_iou(box1, box2):\n",
        "    \"\"\"Visualize two boxes and their IoU.\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    \n",
        "    # Draw boxes\n",
        "    rect1 = patches.Rectangle(\n",
        "        (box1[0], box1[1]), box1[2]-box1[0], box1[3]-box1[1],\n",
        "        linewidth=2, edgecolor='blue', facecolor='blue', alpha=0.3,\n",
        "        label='Box A'\n",
        "    )\n",
        "    rect2 = patches.Rectangle(\n",
        "        (box2[0], box2[1]), box2[2]-box2[0], box2[3]-box2[1],\n",
        "        linewidth=2, edgecolor='red', facecolor='red', alpha=0.3,\n",
        "        label='Box B'\n",
        "    )\n",
        "    \n",
        "    ax.add_patch(rect1)\n",
        "    ax.add_patch(rect2)\n",
        "    \n",
        "    # Calculate and display IoU\n",
        "    iou = calculate_iou(box1, box2)\n",
        "    \n",
        "    ax.set_xlim(-50, 350)\n",
        "    ax.set_ylim(350, -50)\n",
        "    ax.set_title(f'IoU = {iou:.4f}')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.set_aspect('equal')\n",
        "    \n",
        "    return fig\n",
        "\n",
        "# Show different overlap cases\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "cases = [\n",
        "    ((0, 0, 100, 100), (50, 50, 150, 150), \"Partial Overlap\"),\n",
        "    ((0, 0, 100, 100), (200, 200, 300, 300), \"No Overlap\"),\n",
        "    ((0, 0, 100, 100), (25, 25, 125, 125), \"High Overlap\"),\n",
        "]\n",
        "\n",
        "for ax, (box1, box2, title) in zip(axes, cases):\n",
        "    rect1 = patches.Rectangle(\n",
        "        (box1[0], box1[1]), box1[2]-box1[0], box1[3]-box1[1],\n",
        "        linewidth=2, edgecolor='blue', facecolor='blue', alpha=0.3\n",
        "    )\n",
        "    rect2 = patches.Rectangle(\n",
        "        (box2[0], box2[1]), box2[2]-box2[0], box2[3]-box2[1],\n",
        "        linewidth=2, edgecolor='red', facecolor='red', alpha=0.3\n",
        "    )\n",
        "    \n",
        "    ax.add_patch(rect1)\n",
        "    ax.add_patch(rect2)\n",
        "    \n",
        "    iou = calculate_iou(box1, box2)\n",
        "    ax.set_title(f'{title}\\nIoU = {iou:.3f}')\n",
        "    ax.set_xlim(-50, 350)\n",
        "    ax.set_ylim(350, -50)\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why IoU Matters\n",
        "\n",
        "IoU is used everywhere in object detection:\n",
        "\n",
        "1. **Training**: Match predicted boxes to ground truth\n",
        "2. **NMS**: Remove duplicate detections (covered in Lab 7)\n",
        "3. **Evaluation**: Measure model performance (mAP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE: When is a Detection \"Correct\"?\n",
        "\n",
        "# Ground truth (what's actually in the image)\n",
        "ground_truth = (100, 100, 300, 300)\n",
        "\n",
        "# Different predictions\n",
        "predictions = [\n",
        "    (105, 95, 305, 305),   # Good prediction\n",
        "    (150, 150, 350, 350),  # Okay prediction\n",
        "    (250, 250, 400, 400),  # Poor prediction\n",
        "    (400, 400, 500, 500),  # Wrong prediction\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "\n",
        "for ax, pred in zip(axes, predictions):\n",
        "    # Ground truth (green)\n",
        "    gt_rect = patches.Rectangle(\n",
        "        (ground_truth[0], ground_truth[1]), \n",
        "        ground_truth[2]-ground_truth[0], ground_truth[3]-ground_truth[1],\n",
        "        linewidth=2, edgecolor='green', facecolor='green', alpha=0.3,\n",
        "        label='Ground Truth'\n",
        "    )\n",
        "    \n",
        "    # Prediction (blue)\n",
        "    pred_rect = patches.Rectangle(\n",
        "        (pred[0], pred[1]), pred[2]-pred[0], pred[3]-pred[1],\n",
        "        linewidth=2, edgecolor='blue', facecolor='blue', alpha=0.3,\n",
        "        label='Prediction'\n",
        "    )\n",
        "    \n",
        "    ax.add_patch(gt_rect)\n",
        "    ax.add_patch(pred_rect)\n",
        "    \n",
        "    iou = calculate_iou(ground_truth, pred)\n",
        "    status = \"CORRECT\" if iou >= 0.5 else \"WRONG\"\n",
        "    color = 'green' if iou >= 0.5 else 'red'\n",
        "    \n",
        "    ax.set_title(f'IoU = {iou:.3f}\\n{status}', color=color, fontweight='bold')\n",
        "    ax.set_xlim(0, 550)\n",
        "    ax.set_ylim(550, 0)\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "plt.suptitle('Detection is CORRECT if IoU >= 0.5', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 4.1\n",
        "\n",
        "Given these two boxes, calculate the IoU by hand first, then verify with code:\n",
        "- Box A: (10, 10, 50, 50)\n",
        "- Box B: (30, 30, 70, 70)\n",
        "\n",
        "Hint: Draw it on paper first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# Hand calculation:\n",
        "# Area A = ?\n",
        "# Area B = ?\n",
        "# Intersection area = ?\n",
        "# Union area = ?\n",
        "# IoU = ?\n",
        "\n",
        "# Verify with code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Challenge Problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Challenge 1: Process a Video\n",
        "\n",
        "Run YOLO on a video file and count how many times each object class appears across all frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# Download a sample video\n",
        "# video_url = \"https://...\"\n",
        "\n",
        "# Process each frame\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Challenge 2: Object Counting App\n",
        "\n",
        "Create a function that takes an image and returns a dictionary counting each detected object type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "def count_objects(image_path, confidence_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Count objects in an image.\n",
        "    \n",
        "    Returns:\n",
        "        dict: {class_name: count}\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "# Test\n",
        "# counts = count_objects(\"bus.jpg\")\n",
        "# print(counts)  # Expected: {'person': 4, 'bus': 1, ...}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Challenge 3: IoU Matrix\n",
        "\n",
        "Given a list of predicted boxes and ground truth boxes, create an IoU matrix showing the IoU between every pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "def iou_matrix(predictions, ground_truths):\n",
        "    \"\"\"\n",
        "    Calculate IoU between all pairs of boxes.\n",
        "    \n",
        "    Returns:\n",
        "        numpy array of shape (len(predictions), len(ground_truths))\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "# Test\n",
        "# preds = [(0, 0, 50, 50), (100, 100, 150, 150)]\n",
        "# gts = [(5, 5, 55, 55), (90, 90, 140, 140), (200, 200, 250, 250)]\n",
        "# matrix = iou_matrix(preds, gts)\n",
        "# print(matrix.shape)  # (2, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Summary\n",
        "\n",
        "## What We Learned\n",
        "\n",
        "| Concept | Description |\n",
        "|---------|-------------|\n",
        "| **Bounding Box** | Rectangle around an object: (x1, y1, x2, y2) |\n",
        "| **YOLO** | Fast object detector - \"You Only Look Once\" |\n",
        "| **Confidence** | How sure the model is (0 to 1) |\n",
        "| **IoU** | Intersection over Union - measures box overlap |\n",
        "| **Supervision** | Library for beautiful detection visualization |\n",
        "\n",
        "## Key Code Patterns\n",
        "\n",
        "```python\n",
        "# Load YOLO\n",
        "from ultralytics import YOLO\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Run detection\n",
        "results = model(image_path)\n",
        "boxes = results[0].boxes\n",
        "\n",
        "# Visualize with supervision\n",
        "import supervision as sv\n",
        "detections = sv.Detections.from_ultralytics(results[0])\n",
        "annotator = sv.BoxAnnotator()\n",
        "annotated = annotator.annotate(image, detections)\n",
        "\n",
        "# Calculate IoU\n",
        "iou = calculate_iou(box1, box2)\n",
        "```\n",
        "\n",
        "## What's Next?\n",
        "\n",
        "In **Lab 7**, we'll learn about:\n",
        "- Non-Maximum Suppression (NMS)\n",
        "- Fine-tuning YOLO on custom data\n",
        "- Evaluation metrics (mAP)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
