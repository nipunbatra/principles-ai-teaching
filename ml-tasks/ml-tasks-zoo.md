---
marp: true
theme: default
paginate: true
backgroundColor: #fff
style: |
  section {
    font-family: 'Segoe UI', 'Arial', sans-serif;
    font-size: 24px;
    padding: 35px;
    color: #333;
  }
  h1 { color: #2E86AB; font-size: 1.7em; margin-bottom: 0.2em; }
  h2 { color: #06A77D; font-size: 1.1em; margin-top: 0; }
  h3 { color: #457B9D; font-size: 1.0em; }
  strong { color: #D62828; }
  code {
    background: #f4f4f4;
    color: #2E86AB;
    padding: 2px 6px;
    border-radius: 4px;
    font-family: 'Consolas', 'Monaco', monospace;
  }
  pre {
    background: #f8f9fa;
    border-radius: 8px;
    padding: 12px;
    font-size: 0.8em;
    line-height: 1.35;
    overflow: hidden;
  }
  .task {
    background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
    border-left: 4px solid #2E86AB;
    padding: 10px 12px;
    margin: 8px 0;
    border-radius: 0 6px 6px 0;
  }
  .example {
    background: #e8f5e9;
    border-left: 4px solid #06A77D;
    padding: 10px 12px;
    margin: 8px 0;
    border-radius: 0 6px 6px 0;
  }
  .insight {
    background: #fff3cd;
    border-left: 4px solid #ffc107;
    padding: 10px 12px;
    margin: 8px 0;
    border-radius: 0 6px 6px 0;
  }
  .realworld {
    background: #e3f2fd;
    border-left: 4px solid #2196F3;
    padding: 10px 12px;
    margin: 8px 0;
    border-radius: 0 6px 6px 0;
  }
  .warning {
    background: #ffebee;
    border-left: 4px solid #f44336;
    padding: 10px 12px;
    margin: 8px 0;
    border-radius: 0 6px 6px 0;
  }
  .columns { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; }
  .columns3 { display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 15px; }
  table { font-size: 0.85em; width: 100%; }
  th { background: #2E86AB; color: white; padding: 6px; }
  td { padding: 6px; border-bottom: 1px solid #dee2e6; }
---

# The Machine Learning Task Zoo ğŸ¦
## A Safari Through 40+ Real-World AI Problems

**Nipun Batra** Â· IIT Gandhinagar

---

# What We'll Explore Today

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    THE ML TASK SAFARI MAP                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚   ğŸ”· COMPUTER VISION          ğŸ”¶ NATURAL LANGUAGE PROCESSING        â”‚
â”‚   Classification              Sentiment Analysis                    â”‚
â”‚   Detection                   Named Entity Recognition              â”‚
â”‚   Segmentation               Translation                            â”‚
â”‚   Pose Estimation            Summarization                          â”‚
â”‚   Depth Estimation           Question Answering                     â”‚
â”‚                                                                     â”‚
â”‚   ğŸ”· AUDIO & SPEECH           ğŸ”¶ GENERATIVE MODELS                   â”‚
â”‚   Speech-to-Text             Image Generation                       â”‚
â”‚   Text-to-Speech             Text Generation                        â”‚
â”‚   Speaker Recognition        Video Generation                       â”‚
â”‚                                                                     â”‚
â”‚   ğŸ”· REINFORCEMENT            ğŸ”¶ MULTIMODAL                          â”‚
â”‚   Game Playing               Visual QA                              â”‚
â”‚   Robot Control              Image Captioning                       â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# The Universal ML Recipe

Before we dive into 40+ tasks, remember this simple pattern:

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚          EVERY ML TASK              â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   INPUT     â”‚   â”€â”€â”€â–º  â”‚     MODEL       â”‚   â”€â”€â”€â–º  â”‚   OUTPUT    â”‚
â”‚   (X)       â”‚         â”‚    f(X; Î¸)      â”‚         â”‚    (Y)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  What changes between tasks:  â”‚
                    â”‚  â€¢ What X looks like          â”‚
                    â”‚  â€¢ What Y looks like          â”‚
                    â”‚  â€¢ How we measure success     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<div class="insight">
The same Transformer architecture powers ChatGPT, DALL-E, and self-driving cars!
</div>

---

# How to Think About ML Tasks

Every task is defined by **what goes in** and **what comes out**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚   INPUT (X)            MODEL              OUTPUT (Y)            â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”‚
â”‚   Image         â”‚               â”‚     "Cat"                     â”‚
â”‚   Text      â”€â”€â”€â–ºâ”‚   f(x; Î¸)     â”‚â”€â”€â”€â–º 0.87                      â”‚
â”‚   Audio         â”‚               â”‚     [x, y, w, h]              â”‚
â”‚   Numbers       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     "Bonjour"                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<div class="insight">
The same model architecture can solve many different tasks â€” what changes is the data!
</div>

---

# A Simple Classification

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ML TASKS BY INPUT/OUTPUT                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   INPUT TYPE          â†’        OUTPUT TYPE                          â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”‚
â”‚                                                                      â”‚
â”‚   Image               â†’        Label           (Classification)     â”‚
â”‚   Image               â†’        Boxes           (Detection)          â”‚
â”‚   Image               â†’        Pixel Labels    (Segmentation)       â”‚
â”‚   Image               â†’        Text            (Captioning)         â”‚
â”‚   Text                â†’        Label           (Sentiment)          â”‚
â”‚   Text                â†’        Text            (Translation)        â”‚
â”‚   Audio               â†’        Text            (Speech-to-Text)     â”‚
â”‚   Text                â†’        Audio           (Text-to-Speech)     â”‚
â”‚   Numbers             â†’        Number          (Regression)         â”‚
â”‚   Numbers             â†’        Groups          (Clustering)         â”‚
â”‚   Noise               â†’        Image           (Generation)         â”‚
â”‚   Text                â†’        Image           (Text-to-Image)      â”‚
â”‚   Game State          â†’        Action          (RL)                 â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ”· Domain 1: Computer Vision
## Teaching Machines to See

*"A picture is worth a thousand words... to a neural network, it's worth millions of numbers!"*

---

# The Vision Task Hierarchy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                        â”‚
â”‚  LEVEL 1: Classification     "There's a dog somewhere in this image"  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚           Easiest: Just need the answer                                â”‚
â”‚                                                                        â”‚
â”‚  LEVEL 2: Detection          "There's a dog at position (x, y, w, h)" â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚           Harder: Need to locate it with a box                         â”‚
â”‚                                                                        â”‚
â”‚  LEVEL 3: Segmentation       "These exact pixels belong to the dog"   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚           Even harder: Pixel-perfect boundaries                        â”‚
â”‚                                                                        â”‚
â”‚  LEVEL 4: Pose Estimation    "Dog's head is at (xâ‚,yâ‚), legs at ..."  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚           Hardest: Find specific body parts/keypoints                  â”‚
â”‚                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–²
                â”‚
          More precision, more data, more compute needed
```

---

# Let's See This Visually

```
SAME IMAGE, DIFFERENT TASKS:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                       â”‚
â”‚  CLASSIFICATION        DETECTION          SEGMENTATION    POSE       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€       â”‚
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           â”‚        â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”‚       â”‚  â–“â–“â–“â–“â–“    â”‚   â”‚   â—   â”‚  â”‚
â”‚  â”‚   ğŸ•      â”‚        â”‚  â”‚ Dog â”‚  â”‚       â”‚ â–“â–“â–“â–“â–“â–“â–“   â”‚   â”‚  /â”‚\  â”‚  â”‚
â”‚  â”‚           â”‚        â”‚  â”‚ 95% â”‚  â”‚       â”‚â–“â–“â–“â–“â–“â–“â–“â–“â–“  â”‚   â”‚  / \  â”‚  â”‚
â”‚  â”‚           â”‚        â”‚  â””â”€â”€â”€â”€â”€â”˜  â”‚       â”‚ â–“â–“â–“ â–“â–“â–“   â”‚   â”‚ â—   â— â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                       â”‚
â”‚  Output: "Dog"        Output:             Output:         Output:     â”‚
â”‚                       [class, x,y,w,h]    Pixel mask      Keypoints   â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 1: Image Classification

<div class="columns">
<div>

**What:** Assign one label to an image.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚
â”‚   [Photo of     â”‚â”€â”€â–º "Golden Retriever"
â”‚    a dog]       â”‚    Confidence: 94.2%
â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Real-world uses:**
- ğŸ“± Google Photos auto-tagging
- ğŸ¥ Medical X-ray diagnosis
- ğŸ­ Quality control in factories
- ğŸŒ¿ Plant disease detection

</div>
<div>

<div class="example">

**Example: MNIST Digits**
```
Input:  28Ã—28 grayscale image
Output: One of {0, 1, 2, ..., 9}

    â–ˆâ–ˆâ–ˆâ–ˆ
   â–ˆ    â–ˆ
        â–ˆ
       â–ˆ
      â–ˆ
     â–ˆ
     â–ˆ        â†’ "7" (98.5%)
```

10 classes, 60K training images
The "Hello World" of computer vision!

</div>

</div>
</div>

---

# The Math Behind Classification

```
Input Image (e.g., 224 Ã— 224 Ã— 3 = 150,528 numbers)
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Neural Network   â”‚
           â”‚   (millions of     â”‚
           â”‚    parameters)     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
           Raw scores (logits)
           [2.5, -1.2, 8.7, 0.3, ...]  (one per class)
                     â”‚
                     â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚     Softmax       â”‚  â† Converts to probabilities
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
           [0.01, 0.00, 0.94, 0.05, ...]  (sums to 1.0)
                     â”‚
                     â–¼
           Prediction: Class 3 (94% confidence)
```

---

# ImageNet: The Olympics of Image Classification

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        IMAGENET CHALLENGE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚   Dataset:  14 million images, 1000 classes                         â”‚
â”‚                                                                     â”‚
â”‚   Classes include:                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ ğŸ•      â”‚ â”‚ ğŸš—      â”‚ â”‚ ğŸ¸      â”‚ â”‚ ğŸ•      â”‚ â”‚ ğŸ       â”‚     â”‚
â”‚   â”‚ 120 dog â”‚ â”‚ Cars    â”‚ â”‚ Musical â”‚ â”‚ Foods   â”‚ â”‚ Objects â”‚     â”‚
â”‚   â”‚ breeds! â”‚ â”‚         â”‚ â”‚ instr.  â”‚ â”‚         â”‚ â”‚         â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                     â”‚
â”‚   Year    Winner           Top-5 Error    Note                      â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚
â”‚   2010    Traditional ML   28.2%          Hand-crafted features    â”‚
â”‚   2012    AlexNet (CNN)    16.4%          ğŸ”¥ Deep learning begins!  â”‚
â”‚   2015    ResNet           3.6%           Superhuman performance!  â”‚
â”‚   2020    ViT              1.0%           Transformers enter visionâ”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Multi-Label Classification

**Sometimes one label isn't enough!**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚   SINGLE-LABEL                    MULTI-LABEL                       â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                       â”‚
â”‚                                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚   â”‚           â”‚                   â”‚           â”‚                     â”‚
â”‚   â”‚   ğŸ±      â”‚ â†’ "Cat"           â”‚ ğŸ± + ğŸ•   â”‚ â†’ ["Cat", "Dog"]   â”‚
â”‚   â”‚           â”‚   (one class)     â”‚   + ğŸ›‹ï¸    â”‚    ["Couch"]        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   ["Indoors"]       â”‚
â”‚                                                                     â”‚
â”‚   Each image has                  Each image can have               â”‚
â”‚   exactly ONE label               MULTIPLE labels                   â”‚
â”‚                                                                     â”‚
â”‚   Use: Softmax                    Use: Sigmoid (per class)          â”‚
â”‚   Î£ probabilities = 1             Each class: 0 to 1 independently  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<div class="realworld">
**Instagram uses multi-label classification** for their photo tags and content moderation!
</div>

---

# Task 2: Object Detection

<div class="columns">
<div>

**What:** Find objects AND locate them with boxes.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”Œâ”€â”€â”€â”€â”                 â”‚
â”‚  â”‚dog â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚0.95â”‚   â”‚personâ”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”˜   â”‚ 0.91 â”‚      â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Output for each detection:**
- Class label ("dog")
- Confidence score (0.95)
- Bounding box: (x, y, width, height)

</div>
<div>

<div class="example">

**Example: Self-Driving Car**
```
Detections in one frame:
â”œâ”€ Car      at (120, 80)  conf: 0.97
â”œâ”€ Car      at (400, 90)  conf: 0.89
â”œâ”€ Person   at (300, 150) conf: 0.92
â”œâ”€ Bicycle  at (50, 200)  conf: 0.88
â””â”€ Traffic  at (250, 20)  conf: 0.99
   Light

Must process 30+ frames/second!
```

</div>

</div>
</div>

---

# Detection vs Classification: Key Differences

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CLASSIFICATION vs DETECTION                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚   CLASSIFICATION                  DETECTION                         â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚                                                                     â”‚
â”‚   Input:  One image               Input:  One image                 â”‚
â”‚   Output: One label               Output: List of (class, box)      â”‚
â”‚                                                                     â”‚
â”‚   Assumes: Object fills           Handles: Multiple objects,        â”‚
â”‚            most of image                   any size, anywhere       â”‚
â”‚                                                                     â”‚
â”‚   Architecture:                   Architecture:                     â”‚
â”‚   CNN â†’ FC â†’ Softmax              CNN â†’ Multiple detection heads    â”‚
â”‚                                                                     â”‚
â”‚   Example:                        Example:                          â”‚
â”‚   "Is this a cat or dog?"         "Find all cats and dogs"          â”‚
â”‚                                                                     â”‚
â”‚   Popular Models:                 Popular Models:                   â”‚
â”‚   ResNet, EfficientNet            YOLO, Faster R-CNN, DETR          â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# How YOLO Works (Simplified)

**"You Only Look Once" - Fast single-pass detection**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚   Step 1: Divide image into grid (e.g., 7Ã—7)                        â”‚
â”‚                                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”                                    â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚                                    â”‚
â”‚   â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤     Each cell predicts:            â”‚
â”‚   â”‚   â”‚   â”‚ ğŸ•â”‚   â”‚   â”‚   â”‚   â”‚     â€¢ B bounding boxes              â”‚
â”‚   â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤     â€¢ Confidence scores            â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚     â€¢ C class probabilities         â”‚
â”‚   â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤                                    â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚ ğŸ±â”‚   â”‚                                    â”‚
â”‚   â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤                                    â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚                                    â”‚
â”‚   â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜                                    â”‚
â”‚                                                                     â”‚
â”‚   Step 2: Remove overlapping boxes (Non-Max Suppression)            â”‚
â”‚   Step 3: Output final detections                                   â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 3: Semantic Segmentation

**What:** Label every pixel with its class.

```
ORIGINAL IMAGE:                       SEMANTIC SEGMENTATION:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SSSSSSSSSSSSSSSSSSSS â”‚              â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚  â–‘ = Sky
â”‚ SSSSSSSSSSSSSSSSSSSS â”‚              â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚
â”‚                      â”‚              â”‚                      â”‚
â”‚  [Car1]    [Car2]    â”‚     â•â•â•â–º     â”‚  â–“â–“â–“â–“â–“    â–“â–“â–“â–“â–“     â”‚  â–“ = Car
â”‚                      â”‚              â”‚                      â”‚
â”‚ RRRRRRRRRRRRRRRRRRRR â”‚              â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚  â–ˆ = Road
â”‚ RRRRRRRRRRRRRRRRRRRR â”‚              â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Output: An image of same size where each pixel is colored by class
```

<div class="insight">
**Both cars have the same color** â€” semantic segmentation doesn't distinguish between instances of the same class!
</div>

---

# Task 4: Instance Segmentation

**What:** Label every pixel AND distinguish individual objects.

```
SEMANTIC SEGMENTATION:               INSTANCE SEGMENTATION:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚              â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚
â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚              â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚
â”‚                      â”‚              â”‚                      â”‚
â”‚  â–“â–“â–“â–“â–“    â–“â–“â–“â–“â–“     â”‚     vs       â”‚  ğŸ”µğŸ”µğŸ”µ   ğŸŸ¢ğŸŸ¢ğŸŸ¢     â”‚
â”‚                      â”‚              â”‚                      â”‚
â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚              â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚
â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚              â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

 Both cars = same "Car" color          Car #1 = Blue, Car #2 = Green
 Can't tell them apart!                Can track each car individually
```

<div class="realworld">
**Self-driving cars need instance segmentation** â€” you must track which car is which to predict their movements!
</div>

---

# Panoptic Segmentation: The Complete Picture

**Combining everything: Semantic + Instance**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚                     PANOPTIC SEGMENTATION                           â”‚
â”‚                                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ Sky (stuff - no instances)                                 â”‚     â”‚
â”‚   â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚     â”‚
â”‚   â”‚                                                           â”‚     â”‚
â”‚   â”‚    Car #1        Person #1        Car #2                  â”‚     â”‚
â”‚   â”‚    ğŸ”µğŸ”µğŸ”µ         ğŸŸ¡ğŸŸ¡              ğŸŸ¢ğŸŸ¢                  â”‚     â”‚
â”‚   â”‚                                                           â”‚     â”‚
â”‚   â”‚ Road (stuff - no instances)                               â”‚     â”‚
â”‚   â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                     â”‚
â”‚   "Stuff" classes: sky, road, grass (don't count instances)         â”‚
â”‚   "Things" classes: cars, people (each instance gets unique ID)     â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Segmentation Summary

| Task | What it outputs | Can count objects? | Use case |
|------|----------------|-------------------|----------|
| **Semantic** | Pixel classes | No | Land use mapping, medical imaging |
| **Instance** | Pixel + instance IDs | Yes | Object tracking, robotics |
| **Panoptic** | Both combined | Yes for "things" | Autonomous driving |

```
                                   Complexity
                                       â–²
                                       â”‚
                        Panoptic â—     â”‚
                                       â”‚
                     Instance â—        â”‚
                                       â”‚
                    Semantic â—         â”‚
                                       â”‚
                    Detection â—        â”‚
                                       â”‚
              Classification â—         â”‚
                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
                                            Data Needed
```

---

# Task 5: Pose Estimation

**What:** Find body keypoints (skeleton) of humans or animals.

```
Original Photo:                    Detected Skeleton:

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â—  â† Head (nose, eyes, ears)
  â”‚             â”‚                       /â”‚\
  â”‚   Person    â”‚         â”€â”€â–º          / â”‚ \
  â”‚  standing   â”‚                     â—  â—  â—  â† Shoulders
  â”‚   with      â”‚                        â”‚
  â”‚  raised arm â”‚                       / \
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â—   â—  â† Hips
                                      /     \
                                     â—       â—  â† Knees
                                    /         \
                                   â—           â—  â† Ankles

Output: 17 keypoints with (x, y, confidence) each
```

---

# Pose Estimation: Real Applications

<div class="columns">
<div>

**Fitness & Sports**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Squat Form       â”‚
â”‚    Analysis         â”‚
â”‚         â—           â”‚
â”‚        /â”‚\          â”‚
â”‚       / â”‚ \         â”‚
â”‚         â”‚           â”‚
â”‚        â•± â•²          â”‚
â”‚       â—   â—         â”‚
â”‚      â†‘     â†‘        â”‚
â”‚   "Knees too far    â”‚
â”‚    over toes!"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>
<div>

**Other Applications**
- ğŸ¬ Motion capture for movies/games
- ğŸƒ Running form analysis
- ğŸ•º Dance move recognition
- ğŸ¤Ÿ Sign language interpretation
- ğŸ® Controller-free gaming (Kinect)
- ğŸ›¡ï¸ Fall detection for elderly

</div>
</div>

<div class="realworld">
**Apple Fitness+** uses pose estimation to analyze your workout form in real-time!
</div>

---

# Task 6: Depth Estimation

**What:** Predict distance of each pixel from the camera.

```
RGB Image:                         Depth Map:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     â”‚           â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚  â–‘ = Far
â”‚    ğŸ”ï¸ (mountains)   â”‚           â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚      (light)
â”‚                     â”‚           â”‚                     â”‚
â”‚  ğŸŒ³ (trees)         â”‚    â”€â”€â–º    â”‚  â–’â–’â–’â–’â–’â–’            â”‚  â–’ = Medium
â”‚                     â”‚           â”‚                     â”‚
â”‚ ğŸš— (close car)      â”‚           â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        â”‚  â–ˆ = Close
â”‚                     â”‚           â”‚                     â”‚      (dark)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Output: Same-size image where pixel intensity = distance
```

<div class="insight">
**One camera, 3D understanding!** Traditional 3D sensing requires special hardware (LiDAR, stereo cameras), but AI can estimate depth from a single RGB image.
</div>

---

# Depth Estimation: How It's Used

<div class="columns3">
<div>

**AR/VR**
```
Place virtual
furniture in
your room!

   ğŸ›‹ï¸
   (knows it's
   on the floor)
```

</div>
<div>

**Portrait Mode**
```
Blur background
based on depth

  ğŸ‘¤ (sharp)
  â–‘â–‘â–‘ (blurred)
```

</div>
<div>

**Robotics**
```
Navigate without
bumping into
objects

  ğŸ¤– â†’ ğŸ“¦
  (knows distance)
```

</div>
</div>

**The iPhone's Portrait Mode** uses a combination of depth sensors AND neural network depth estimation!

---

# Task 7: Optical Flow

**What:** Track how each pixel moves between video frames.

```
Frame t:                Frame t+1:              Flow Vectors:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              â”‚       â”‚              â”‚        â”‚              â”‚
â”‚   â—          â”‚  â”€â”€â–º  â”‚        â—     â”‚   =    â”‚   â”€â”€â”€â”€â”€â”€â”€â–º   â”‚
â”‚   (ball)     â”‚       â”‚   (ball)     â”‚        â”‚              â”‚
â”‚              â”‚       â”‚              â”‚        â”‚              â”‚
â”‚        â–²     â”‚       â”‚    â–²         â”‚        â”‚        â—„â”€â”€   â”‚
â”‚     (person) â”‚       â”‚ (person)     â”‚        â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                               Each pixel gets
                                               a motion vector
```

**Key insight:** Every pixel gets a (dx, dy) vector showing where it moved!

---

# Optical Flow Applications

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      OPTICAL FLOW USE CASES                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  ğŸ¬ VIDEO COMPRESSION                                                â”‚
â”‚  Instead of storing every frame, store keyframes + motion vectors   â”‚
â”‚  Result: 10x smaller file sizes                                     â”‚
â”‚                                                                      â”‚
â”‚  ğŸƒ ACTION RECOGNITION                                               â”‚
â”‚  "Running" = specific pattern of flow vectors                       â”‚
â”‚  "Waving" = different pattern                                       â”‚
â”‚                                                                      â”‚
â”‚  ğŸš— AUTONOMOUS DRIVING                                               â”‚
â”‚  Objects moving towards you â†’ collision warning                     â”‚
â”‚  Everything moving left â†’ you're turning right                      â”‚
â”‚                                                                      â”‚
â”‚  ğŸ® VIDEO GAMES                                                      â”‚
â”‚  Frame interpolation: turn 30fps into 60fps                         â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 8: Face Recognition

**What:** Identify WHO a face belongs to.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               â”‚      â”‚                                           â”‚
â”‚    [Face      â”‚ â”€â”€â”€â–º â”‚   Face Embedding: [0.23, -0.41, 0.87, ...â”‚
â”‚     Image]    â”‚      â”‚   (128-dimensional vector)                â”‚
â”‚               â”‚      â”‚                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Compare with database        â”‚
                        â”‚                               â”‚
                        â”‚  Distance to "Nipun": 0.15   â”‚ â† Match!
                        â”‚  Distance to "Alice": 0.89   â”‚
                        â”‚  Distance to "Bob":   0.92   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
                              "Match: Nipun Batra"
```

---

# Face Detection â‰  Face Recognition

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚   FACE DETECTION                    FACE RECOGNITION                â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚
â”‚                                                                     â”‚
â”‚   Question: "Where are              Question: "Who is               â”‚
â”‚              the faces?"                       this person?"        â”‚
â”‚                                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”            â”‚            â”‚      â”Œâ”€â”€â”€â”        â”‚            â”‚
â”‚   â”‚  â”‚ ? â”‚   â”Œâ”€â”€â”€â”    â”‚            â”‚      â”‚ ğŸ‘¤ â”‚        â”‚            â”‚
â”‚   â”‚  â””â”€â”€â”€â”˜   â”‚ ? â”‚    â”‚            â”‚      â””â”€â”€â”€â”˜        â”‚            â”‚
â”‚   â”‚          â””â”€â”€â”€â”˜    â”‚            â”‚        â†“          â”‚            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚   "This is Nipun" â”‚            â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚   Output: Bounding boxes           Output: Identity label           â”‚
â”‚                                                                     â”‚
â”‚   Used BEFORE recognition          Requires database of             â”‚
â”‚   (find faces first)               known faces                      â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Vision Tasks Summary

| Task | Input | Output | Example Use |
|------|-------|--------|-------------|
| Classification | Image | Label | "Is this spam?" |
| Detection | Image | Boxes + labels | Self-driving cars |
| Segmentation | Image | Pixel mask | Medical imaging |
| Pose Estimation | Image | Keypoints | Fitness apps |
| Depth Estimation | Image | Depth map | AR furniture |
| Optical Flow | 2 frames | Motion vectors | Video compression |
| Face Recognition | Face | Identity | Phone unlock |

---

# ğŸ”¶ Domain 2: Natural Language Processing
## Teaching Machines to Read & Write

*"Language is the dress of thought."* â€” Samuel Johnson

---

# The NLP Task Landscape

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         NLP TASKS                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   UNDERSTANDING TASKS              GENERATION TASKS                  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚                                                                      â”‚
â”‚   â€¢ Sentiment Analysis             â€¢ Text Generation                 â”‚
â”‚     (Is this positive?)              (Write like Shakespeare)       â”‚
â”‚                                                                      â”‚
â”‚   â€¢ Named Entity Recognition       â€¢ Summarization                   â”‚
â”‚     (Find names, places, dates)      (Shorten this article)         â”‚
â”‚                                                                      â”‚
â”‚   â€¢ Question Answering             â€¢ Translation                     â”‚
â”‚     (Find the answer)                (English â†’ Hindi)              â”‚
â”‚                                                                      â”‚
â”‚   â€¢ Topic Classification           â€¢ Paraphrasing                    â”‚
â”‚     (Sports? Politics? Tech?)        (Same meaning, new words)      â”‚
â”‚                                                                      â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                      â”‚
â”‚   MODERN LLMS CAN DO ALL OF THESE WITH A SINGLE MODEL!              â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 9: Sentiment Analysis

**What:** Classify text by emotion/opinion.

<div class="columns">
<div>

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "This movie was absolutely  â”‚
â”‚  amazing! Best film of the  â”‚
â”‚  year. A masterpiece!"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ POSITIVE  â”‚
         â”‚  (0.96)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>
<div>

<div class="example">

**Output Options:**
```
Binary:     Positive / Negative

3-class:    Positive / Neutral /
            Negative

5-class:    â­ to â­â­â­â­â­

Continuous: -1.0 to +1.0
            (very negative â†’
             very positive)
```

</div>

</div>
</div>

---

# Sentiment Analysis: Real World

<div class="columns">
<div>

**Brand Monitoring**
```
Twitter Stream:
â”œâ”€ "Love the new iPhone!" â†’ ğŸ˜Š
â”œâ”€ "Battery dies so fast" â†’ ğŸ˜ 
â”œâ”€ "Just bought one!"     â†’ ğŸ˜
â”œâ”€ "Worst purchase ever"  â†’ ğŸ˜ 
â””â”€ "Camera is incredible" â†’ ğŸ˜Š

Daily Sentiment: 67% positive
```

</div>
<div>

**Customer Feedback**
```
Support Tickets:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Urgent (Negative) â—â—â—â—  â”‚
â”‚ Normal  (Neutral) â—â—    â”‚
â”‚ Praise  (Positive) â—    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â†’ Route angry customers
  to senior support!
```

</div>
</div>

<div class="realworld">
**Amazon analyzes millions of reviews** using sentiment analysis to understand product reception!
</div>

---

# The Challenge: Sarcasm & Context

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      WHY SENTIMENT IS HARD                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  SARCASM:                                                            â”‚
â”‚  "Oh great, another software update. Just what I needed."            â”‚
â”‚   Words: positive ("great", "needed")                                â”‚
â”‚   Meaning: NEGATIVE                                                  â”‚
â”‚                                                                      â”‚
â”‚  NEGATION:                                                           â”‚
â”‚  "This movie is not bad."                                            â”‚
â”‚   Contains "bad" â†’ but overall POSITIVE                              â”‚
â”‚                                                                      â”‚
â”‚  CONTEXT:                                                            â”‚
â”‚  "The battery lasts forever" (phone review) â†’ POSITIVE               â”‚
â”‚  "This movie lasts forever" (movie review) â†’ NEGATIVE                â”‚
â”‚                                                                      â”‚
â”‚  MIXED:                                                              â”‚
â”‚  "The food was great but the service was terrible."                  â”‚
â”‚   Overall? Positive? Negative? Neutral? Depends on priority!         â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 10: Named Entity Recognition (NER)

**What:** Find and label names, places, dates, organizations, etc.

```
Input:  "Elon Musk announced that Tesla will open a factory
         in Berlin by March 2025."

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”
        â”‚ PERSON â”‚                    â”‚  ORG  â”‚
        â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”¬â”€â”€â”€â”˜
            â”‚                             â”‚
            â–¼                             â–¼
Output: "Elon Musk announced that Tesla will open a factory

                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚  LOC  â”‚ â”‚   DATE   â”‚
                                        â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                            â”‚          â”‚
                                            â–¼          â–¼
         in Berlin by March 2025."
```

---

# NER: Entity Types

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMMON NER ENTITY TYPES                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   TYPE          EXAMPLES                      COLOR CODE             â”‚
â”‚   â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚   PERSON        Elon Musk, Marie Curie        ğŸŸ¦ Blue                â”‚
â”‚   ORGANIZATION  Tesla, Google, UN             ğŸŸ© Green               â”‚
â”‚   LOCATION      Berlin, Mount Everest         ğŸŸ¨ Yellow              â”‚
â”‚   DATE          March 2025, last Tuesday      ğŸŸ§ Orange              â”‚
â”‚   MONEY         $5 million, â‚¬100              ğŸŸ« Brown               â”‚
â”‚   PERCENT       15%, three percent            â¬œ White               â”‚
â”‚   TIME          3:30 PM, midnight             ğŸŸª Purple              â”‚
â”‚   PRODUCT       iPhone 15, Model S            ğŸŸ¥ Red                 â”‚
â”‚                                                                      â”‚
â”‚   Domain-specific:                                                   â”‚
â”‚   - Medical: DISEASE, DRUG, SYMPTOM                                  â”‚
â”‚   - Legal: CASE_NUMBER, COURT, JUDGE                                 â”‚
â”‚   - Finance: TICKER, EXCHANGE, CURRENCY                              â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# NER: Real Applications

<div class="columns">
<div>

**Search Engines**
```
Query: "restaurants near
        Eiffel Tower"

NER finds:
â””â”€ LOCATION: "Eiffel Tower"

â†’ Shows map of Paris
â†’ Lists nearby restaurants
```

</div>
<div>

**Knowledge Graphs**
```
Text: "Tim Cook is the
       CEO of Apple"

Extracted:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚Tim Cook â”‚â”€â”€â”€â”€â–ºâ”‚ Apple â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜CEO  â””â”€â”€â”€â”€â”€â”€â”€â”˜
   PERSON    of    ORG
```

</div>
</div>

<div class="realworld">
**Google Search** uses NER to understand your queries and build its Knowledge Graph!
</div>

---

# Task 11: Machine Translation

**What:** Convert text from one language to another.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ English:                            â”‚
â”‚ "The weather is beautiful today"    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Transformer  â”‚
         â”‚   (Encoder +  â”‚
         â”‚    Decoder)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hindi:                              â”‚
â”‚ "à¤†à¤œ à¤®à¥Œà¤¸à¤® à¤¬à¤¹à¥à¤¤ à¤¸à¥à¤‚à¤¦à¤° à¤¹à¥ˆ"                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Translation Challenges

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WHY TRANSLATION IS HARD                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  WORD ORDER:                                                         â”‚
â”‚  English: "I eat an apple"     (Subject-Verb-Object)                 â”‚
â”‚  Japanese: "ç§ã¯ã‚Šã‚“ã”ã‚’é£Ÿã¹ã‚‹"   (Subject-Object-Verb)                  â”‚
â”‚                                                                      â”‚
â”‚  IDIOMS:                                                             â”‚
â”‚  "It's raining cats and dogs" â†’ Not about animals!                   â”‚
â”‚  Must translate the MEANING, not words                               â”‚
â”‚                                                                      â”‚
â”‚  CONTEXT:                                                            â”‚
â”‚  "The bank is by the river"                                          â”‚
â”‚  - bank = financial institution? river bank?                         â”‚
â”‚                                                                      â”‚
â”‚  CULTURAL CONCEPTS:                                                  â”‚
â”‚  Some words have no direct translation                               â”‚
â”‚  - Japanese "æœ¨æ¼ã‚Œæ—¥" (komorebi): sunlight filtering through trees    â”‚
â”‚                                                                      â”‚
â”‚  GENDER/FORMALITY:                                                   â”‚
â”‚  "You" in English = tu/vous in French (formal vs informal)           â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 12: Text Summarization

<div class="columns">
<div>

**Extractive:** Pick important sentences verbatim.

```
Long Article:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Sentence 1          â”‚ â† Keep
â”‚ Sentence 2          â”‚
â”‚ Sentence 3          â”‚
â”‚ Sentence 4          â”‚ â† Keep
â”‚ Sentence 5          â”‚
â”‚ Sentence 6          â”‚ â† Keep
â”‚ ...                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Just highlights!
No new words created.
```

</div>
<div>

**Abstractive:** Generate new text (paraphrase).

```
Long Article:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Original 1000      â”‚
â”‚  words about        â”‚
â”‚  climate change...] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ AI rewrites
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "Climate scientists â”‚
â”‚  warn that global   â”‚
â”‚  temperatures..."   â”‚
â”‚  (100 words)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>
</div>

<div class="insight">
LLMs like GPT-4 and Claude do **abstractive** summarization â€” they truly understand and paraphrase!
</div>

---

# Task 13: Question Answering

<div class="columns">
<div>

**Extractive QA:**
Find answer span in given text.

```
Context: "Albert Einstein
was born in Ulm, Germany
on March 14, 1879."

Question: "Where was
Einstein born?"

Answer: "Ulm, Germany"
        â–²
        â””â”€â”€ Highlighted from
            the context text
```

</div>
<div>

**Generative QA:**
Generate free-form answer.

```
Question: "Explain
quantum entanglement
to a 5-year-old."

Answer: "Imagine you have
two magic coins. When
you flip one and it
lands on heads, the
other one ALWAYS lands
on heads too, even if
it's on the moon!"
        â–²
        â””â”€â”€ Created new text
            (not from any doc)
```

</div>
</div>

---

# QA: The Evolution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QUESTION ANSWERING EVOLUTION                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   ERA 1: Rule-Based (1960s-2000s)                                   â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚   Keywords â†’ Database lookup â†’ Template answer                       â”‚
â”‚   "Very brittle, only worked for specific domains"                   â”‚
â”‚                                                                      â”‚
â”‚   ERA 2: Extractive (2016-2020)                                     â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚
â”‚   BERT-style: "Find the answer IN the text"                         â”‚
â”‚   Great for reading comprehension tasks                              â”‚
â”‚                                                                      â”‚
â”‚   ERA 3: Generative (2020-present)                                  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚   LLMs: Generate answers from learned knowledge                      â”‚
â”‚   Can answer questions about ANYTHING                                â”‚
â”‚   Can reason, explain, and elaborate                                 â”‚
â”‚                                                                      â”‚
â”‚   ERA 4: RAG (Retrieval-Augmented Generation)                        â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚   LLM + Search = Best of both worlds                                 â”‚
â”‚   Accurate, up-to-date, with sources                                 â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 14: Text Generation (LLMs)

**What:** Predict and generate the next tokens, one at a time.

```
Prompt:  "The secret to happiness is"
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      LLM        â”‚
    â”‚  (GPT, Claude,  â”‚
    â”‚   Gemini, etc.) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
Token 1: "not"     P("not" | prompt) = 0.15
             â”‚
             â–¼
Token 2: "in"      P("in" | prompt + "not") = 0.42
             â”‚
             â–¼
Token 3: "wealth"  P("wealth" | ... + "in") = 0.23
             â”‚
             â–¼
         ... continues until <END> token

Output: "The secret to happiness is not in wealth but in
         meaningful connections with others."
```

---

# How LLMs Generate Text

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AUTOREGRESSIVE GENERATION                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   Step 1: "The"       â†’ predict next â†’ "secret"                      â”‚
â”‚   Step 2: "The secret" â†’ predict next â†’ "to"                         â”‚
â”‚   Step 3: "The secret to" â†’ predict next â†’ "happiness"               â”‚
â”‚   ...                                                                â”‚
â”‚                                                                      â”‚
â”‚   Each step:                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚  Probability Distribution Over Vocabulary           â”‚           â”‚
â”‚   â”‚                                                      â”‚           â”‚
â”‚   â”‚  P("the")      = 0.02  â–‘                            â”‚           â”‚
â”‚   â”‚  P("happiness")= 0.25  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     â”‚           â”‚
â”‚   â”‚  P("success")  = 0.18  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       â”‚           â”‚
â”‚   â”‚  P("life")     = 0.12  â–ˆâ–ˆâ–ˆâ–ˆ                         â”‚           â”‚
â”‚   â”‚  P("love")     = 0.08  â–ˆâ–ˆâ–ˆ                          â”‚           â”‚
â”‚   â”‚  ...           = ...                                 â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                      â”‚
â”‚   Sample from this distribution (or take argmax)                     â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# NLP Tasks Summary

| Task | Input | Output | Key Challenge |
|------|-------|--------|---------------|
| Sentiment | Text | Positive/Negative | Sarcasm, context |
| NER | Text | Entity spans + types | Ambiguous names |
| Translation | Text (lang A) | Text (lang B) | Word order, idioms |
| Summarization | Long text | Short text | Keeping key info |
| QA | Question + context | Answer | Finding relevant info |
| Generation | Prompt | Continued text | Coherence, factuality |

---

# ğŸ”· Domain 3: Audio & Speech
## Teaching Machines to Hear

*"The human voice is the most beautiful instrument of all."* â€” Arvo PÃ¤rt

---

# Task 15: Speech-to-Text (ASR)

**What:** Convert spoken audio to text.

```
Audio Waveform:                          Text Output:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿â•±â•²âˆ¿âˆ¿âˆ¿â•±â•²â•²âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿â•±â•²âˆ¿  â”‚
â”‚ âˆ¿âˆ¿â•±â•²âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿â•±â•²âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿  â”‚  â”€â”€â–º  "Hello, how are
â”‚âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿â•±â•²â•²â•²âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿  â”‚        you today?"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Pipeline:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ Audio â”‚â”€â”€â”€â–ºâ”‚ Spectrogramâ”‚â”€â”€â”€â–ºâ”‚ Encoder â”‚â”€â”€â”€â–ºâ”‚ Decoderâ”‚â”€â”€â”€â–ºâ”‚ Text â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜
 Waveform     Time-Frequency    Features      Language      Words
              representation                   model
```

---

# ASR: The Spectrogram

**Converting sound to "images" that neural networks can process**

```
Audio Wave:                              Spectrogram:
                                         (time â†’ frequency "image")
  â†‘
Amplitude                                Frequency
  â”‚    â•±â•²    â•±â•²    â•±â•²                        â†‘
  â”‚   â•±  â•²  â•±  â•²  â•±  â•²       â”€â”€â”€â”€â”€â”€â”€â–º   High â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
  â”‚  â•±    â•²â•±    â•²â•±    â•²                      â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
  â”‚ â•±                  â•²                     â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Time           Low â”‚ â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆ
                                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
                                                  Time

Bright areas = loud frequencies at that moment
Pattern = unique "fingerprint" of each word!
```

<div class="realworld">
**Whisper by OpenAI** can transcribe audio in 99 languages with near-human accuracy!
</div>

---

# Task 16: Text-to-Speech (TTS)

**What:** Convert text to natural-sounding audio.

```
Text Input:                             Audio Output:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "Welcome to the     â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  future of AI.      â”‚      â”€â”€â–º       â”‚  âˆ¿âˆ¿âˆ¿â•±â•²âˆ¿âˆ¿âˆ¿â•±â•²â•²âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿  â”‚
â”‚  This is exciting!" â”‚                â”‚ âˆ¿â•±â•²âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿â•±â•²âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Modern TTS Pipeline:
â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Text â”‚â”€â”€â”€â–ºâ”‚ Text       â”‚â”€â”€â”€â–ºâ”‚ Acoustic    â”‚â”€â”€â”€â–ºâ”‚ Vocoder  â”‚â”€â”€â”€â–º Audio
â””â”€â”€â”€â”€â”€â”€â”˜    â”‚ Analysis   â”‚    â”‚ Model       â”‚    â”‚ (Neural) â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            (pronunciation,   (generates         (converts to
             emphasis)        mel-spectrogram)    waveform)
```

---

# TTS: Then vs Now

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TTS EVOLUTION                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   1990s: Concatenative TTS                                          â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚   Splice together recorded phonemes                                  â”‚
â”‚   Result: Robotic, unnatural "The-wea-ther-to-day-is..."            â”‚
â”‚                                                                      â”‚
â”‚   2010s: Statistical Parametric TTS                                 â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚   HMM-based models, smoother but still artificial                    â”‚
â”‚                                                                      â”‚
â”‚   2016: WaveNet (DeepMind)                                          â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚   Neural network generates audio sample by sample                    â”‚
â”‚   Human-like quality, but VERY slow                                  â”‚
â”‚                                                                      â”‚
â”‚   2020s: Parallel Neural TTS                                        â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚   Real-time, expressive, can clone voices                            â”‚
â”‚   Examples: ElevenLabs, Bark, XTTS                                   â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 17-18: Speaker Recognition

<div class="columns">
<div>

**Speaker Identification:**
Who is speaking? (1-of-N)

```
Voice Sample
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Voice Encoder   â”‚
â”‚  â†’ Embedding     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
   Compare to database
   of N known speakers
         â”‚
         â–¼
   "Speaker: Alice"
```

</div>
<div>

**Speaker Verification:**
Is this who they claim to be?

```
Voice + "I am Alice"
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Voice Encoder   â”‚
â”‚  â†’ Embedding     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
   Compare to Alice's
   stored voiceprint
         â”‚
         â–¼
   âœ… Verified  or  âŒ Rejected
```

</div>
</div>

<div class="insight">
"Hey Siri" uses **speaker verification** â€” it only responds to the device owner's voice!
</div>

---

# ğŸ”¶ Domain 4: Unsupervised Learning
## Finding Patterns Without Labels

*"The goal is to find structure in chaos."*

---

# Task 19: Clustering

**What:** Group similar items together automatically (no labels needed!).

```
Before (unlabeled data):            After (3 clusters found):

    â€¢    â–                               â—‹    â–¡          â—‹ = Cluster 1
  â€¢   â€¢    â–  â–                         â—‹   â—‹    â–¡ â–¡      â–¡ = Cluster 2
    â€¢        â–                           â—‹        â–¡      â–³ = Cluster 3

        â–²   â–²                              â–³   â–³
    â–²          â–²                       â–³          â–³
      â–²    â–²                             â–³    â–³

Algorithm (K-Means) figures out:
- There are 3 natural groups
- Which points belong to which group
```

---

# Clustering: The K-Means Algorithm

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    K-MEANS: STEP BY STEP                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  Step 1: Pick K random "centroids" (cluster centers)                â”‚
â”‚          â˜…                    â˜…                                      â”‚
â”‚                       â˜…                                              â”‚
â”‚                                                                      â”‚
â”‚  Step 2: Assign each point to nearest centroid                       â”‚
â”‚          â—‹â—‹â—‹ near â˜…â‚    â–¡â–¡â–¡ near â˜…â‚‚    â–³â–³â–³ near â˜…â‚ƒ                   â”‚
â”‚                                                                      â”‚
â”‚  Step 3: Move centroids to center of their points                    â”‚
â”‚          â˜…â‚ moves to average of â—‹â—‹â—‹                                  â”‚
â”‚          â˜…â‚‚ moves to average of â–¡â–¡â–¡                                  â”‚
â”‚          â˜…â‚ƒ moves to average of â–³â–³â–³                                  â”‚
â”‚                                                                      â”‚
â”‚  Step 4: Repeat steps 2-3 until centroids stop moving               â”‚
â”‚                                                                      â”‚
â”‚  Done! Points are now clustered.                                     â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Clustering: Real Applications

<div class="columns">
<div>

**Customer Segmentation**
```
Cluster 1: "VIPs"
â”œâ”€ High spending
â”œâ”€ Infrequent visits
â””â”€ Premium products

Cluster 2: "Regulars"
â”œâ”€ Medium spending
â”œâ”€ Weekly visits
â””â”€ Staple items

Cluster 3: "Bargain Hunters"
â”œâ”€ Low spending
â”œâ”€ Sale days only
â””â”€ Discounted items
```

</div>
<div>

**Image Compression**
```
Original: 16 million colors

After K-Means (K=16):
Only 16 colors!

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”´ğŸŸ ğŸŸ¡ğŸŸ¢ğŸ”µğŸŸ£â¬›â¬œâ”‚
â”‚ and 8 more shades â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

File size: 10x smaller
Quality: Still looks good!
```

</div>
</div>

---

# Task 20: Anomaly Detection

**What:** Find the outliers / unusual patterns.

```
Normal Transactions:                 Anomaly Alert!
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                           â”‚
â”‚  $50  $120  $45  $200  $75  $90  $15,000  $80  $110      â”‚
â”‚   â—     â—    â—     â—    â—    â—      â˜…       â—     â—      â”‚
â”‚                                     â–²                     â”‚
â”‚                                     â”‚                     â”‚
â”‚                              ğŸš¨ FRAUD ALERT!              â”‚
â”‚                              Unusual transaction          â”‚
â”‚                              detected!                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<div class="insight">
Anomaly detection is "learning what's normal, then flagging what's not."
</div>

---

# Anomaly Detection: Methods

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ANOMALY DETECTION APPROACHES                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  1. STATISTICAL                                                      â”‚
â”‚     If value is > 3 standard deviations from mean â†’ Anomaly         â”‚
â”‚     Simple but assumes normal distribution                           â”‚
â”‚                                                                      â”‚
â”‚  2. DISTANCE-BASED                                                   â”‚
â”‚     If point is far from all other points â†’ Anomaly                 â”‚
â”‚     Works for any shape of data                                      â”‚
â”‚                                                                      â”‚
â”‚  3. DENSITY-BASED                                                    â”‚
â”‚     If point is in a low-density region â†’ Anomaly                   â”‚
â”‚     Good for varying cluster sizes                                   â”‚
â”‚                                                                      â”‚
â”‚  4. AUTOENCODER (Neural Network)                                     â”‚
â”‚     Train to reconstruct normal data                                 â”‚
â”‚     High reconstruction error â†’ Anomaly                              â”‚
â”‚     Best for complex, high-dimensional data                          â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 21: Dimensionality Reduction

**What:** Compress high-dimensional data while preserving structure.

```
Original: 784 dimensions (28Ã—28 MNIST image)

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ [0.12, 0.45, 0.00, 0.87, 0.33, ....     â”‚
    â”‚  0.23, 0.00, 0.91, 0.14, .... (784)]    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚  PCA / t-SNE / UMAP
                         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              [0.45, -0.23]              â”‚  â† Just 2D!
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              Now we can visualize it!

         â€¢â€¢ â€¢â€¢                    â† Cluster of "0"s
        â€¢â€¢  â€¢â€¢
          â–²â–² â–²â–²â–²                  â† Cluster of "1"s
            â– â–  â– â–                  â† Cluster of "7"s
```

---

# Why Reduce Dimensions?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BENEFITS OF DIMENSIONALITY REDUCTION              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  1. VISUALIZATION                                                    â”‚
â”‚     Can't plot 784D data, but can plot 2D!                          â”‚
â”‚     Reveal clusters and patterns to humans                           â”‚
â”‚                                                                      â”‚
â”‚  2. SPEED                                                            â”‚
â”‚     ML on 10 features is 100x faster than 1000 features             â”‚
â”‚     Less computation, less memory                                    â”‚
â”‚                                                                      â”‚
â”‚  3. NOISE REMOVAL                                                    â”‚
â”‚     Lower dimensions often capture signal, remove noise              â”‚
â”‚     Can improve model accuracy!                                      â”‚
â”‚                                                                      â”‚
â”‚  4. THE CURSE OF DIMENSIONALITY                                      â”‚
â”‚     As dimensions â†‘, distance between points â†’ same                 â”‚
â”‚     Need exponentially more data in high dimensions                  â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PCA vs t-SNE vs UMAP

| Method | Speed | Preserves | Best For |
|--------|-------|-----------|----------|
| **PCA** | Very fast | Global structure | Initial exploration |
| **t-SNE** | Slow | Local clusters | Visualizing clusters |
| **UMAP** | Fast | Both local + global | Best overall |

```
Same data, different methods:

PCA:                    t-SNE:                  UMAP:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢â€¢ â€¢â€¢       â”‚        â”‚   â—â—        â”‚         â”‚   â—â—        â”‚
â”‚  â—â—  â—â—     â”‚        â”‚  â—â—â—        â”‚         â”‚   â—â—        â”‚
â”‚    â–²â–²       â”‚        â”‚             â”‚         â”‚             â”‚
â”‚   â–²â–²        â”‚        â”‚   â–²â–²â–²       â”‚         â”‚  â–²â–²         â”‚
â”‚  â– â–          â”‚        â”‚  â–²â–²         â”‚         â”‚ â–²â–²â–²         â”‚
â”‚ â– â–           â”‚        â”‚      â– â– â–     â”‚         â”‚      â– â–      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚     â– â–       â”‚         â”‚     â– â– â–      â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Linear projection      Clusters tight         Clusters + structure
```

---

# ğŸ”· Domain 5: Generative Models
## Creating New Content

*"Creativity is just connecting things."* â€” Steve Jobs

---

# The Generative AI Revolution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GENERATIVE AI TIMELINE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   2014: GANs invented                                                â”‚
â”‚         First realistic image generation                             â”‚
â”‚                                                                      â”‚
â”‚   2020: GPT-3 launches                                              â”‚
â”‚         Text generation goes mainstream                              â”‚
â”‚                                                                      â”‚
â”‚   2022: DALL-E 2, Stable Diffusion, Midjourney                      â”‚
â”‚         Anyone can generate images from text                         â”‚
â”‚                                                                      â”‚
â”‚   2022: ChatGPT launches                                            â”‚
â”‚         100M users in 2 months (fastest ever)                        â”‚
â”‚                                                                      â”‚
â”‚   2023: GPT-4, Claude, Gemini                                       â”‚
â”‚         Multimodal: text + images + code                             â”‚
â”‚                                                                      â”‚
â”‚   2024: Sora (video), Suno (music)                                  â”‚
â”‚         Generate any media type from text                            â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 22: Image Generation

**What:** Create new images from noise, text, or other images.

```
Text-to-Image (Stable Diffusion, DALL-E, Midjourney):

Prompt: "A robot painting                  Generated Image:
         a sunset, oil                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         painting style"                   â”‚                     â”‚
              â”‚                            â”‚    ğŸ¤– ğŸ¨ ğŸŒ…         â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚                     â”‚
                                           â”‚  [Beautiful AI      â”‚
                                           â”‚   generated art]    â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Noise-to-Image (GANs, Diffusion):

Random Noise â”€â”€â–º Generator â”€â”€â–º Realistic Image
 [z ~ N(0,1)]                  (faces, landscapes, art...)
```

---

# How Diffusion Models Work

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DIFFUSION: THE CORE IDEA                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   TRAINING (Forward process):                                        â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚   Take image â†’ gradually add noise â†’ pure noise                      â”‚
â”‚                                                                      â”‚
â”‚   ğŸ–¼ï¸ â”€â”€â–º ğŸ–¼ï¸+â–‘ â”€â”€â–º ğŸ–¼ï¸+â–’ â”€â”€â–º ğŸ–¼ï¸+â–“ â”€â”€â–º â–“â–“â–“â–“â–“                           â”‚
â”‚   Clean    Slight   Medium   Heavy    Pure                           â”‚
â”‚   image    noise    noise    noise    noise                          â”‚
â”‚                                                                      â”‚
â”‚   GENERATION (Reverse process):                                      â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚   Start with noise â†’ gradually denoise â†’ clean image                 â”‚
â”‚                                                                      â”‚
â”‚   â–“â–“â–“â–“â–“ â”€â”€â–º ğŸ–¼ï¸+â–“ â”€â”€â–º ğŸ–¼ï¸+â–’ â”€â”€â–º ğŸ–¼ï¸+â–‘ â”€â”€â–º ğŸ–¼ï¸                           â”‚
â”‚   Pure      Heavy    Medium   Slight   Clean                         â”‚
â”‚   noise     noise    noise    noise    image!                        â”‚
â”‚                                                                      â”‚
â”‚   The model learns: "Given noisy image, predict the noise"           â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 23: Image Inpainting

**What:** Fill in missing or masked regions intelligently.

```
Original with hole:                  Inpainted result:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         â”‚         â”‚                         â”‚
â”‚    ğŸ”ï¸  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         â”‚   â”€â”€â–º   â”‚    ğŸ”ï¸  â˜€ï¸ with clouds   â”‚
â”‚       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          â”‚         â”‚       blue sky...       â”‚
â”‚                         â”‚         â”‚                         â”‚
â”‚    ğŸŒ²  ğŸ   ğŸŒ²           â”‚         â”‚    ğŸŒ²  ğŸ   ğŸŒ²           â”‚
â”‚                         â”‚         â”‚                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   (user painted a mask)              (AI filled it in)
```

**Uses:**
- ğŸ§¹ Remove unwanted objects (photobombers!)
- ğŸ–¼ï¸ Restore damaged/old photos
- â¬†ï¸ Extend image boundaries (outpainting)

---

# Task 24: Style Transfer

**What:** Apply the artistic style of one image to the content of another.

```
Content Image:          Style Image:           Result:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               â”‚      â”‚               â”‚      â”‚               â”‚
â”‚  [Photo of    â”‚  +   â”‚  [Van Gogh's  â”‚  =   â”‚  [Photo with  â”‚
â”‚   a bridge]   â”‚      â”‚   Starry      â”‚      â”‚   swirly      â”‚
â”‚               â”‚      â”‚   Night]      â”‚      â”‚   brushwork]  â”‚
â”‚               â”‚      â”‚               â”‚      â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

The model learns to separate:
- CONTENT: What objects are in the image (bridge, sky, water)
- STYLE: How they're rendered (brushstrokes, colors, texture)
```

---

# Task 25: Super Resolution

**What:** Upscale low-resolution images while adding realistic detail.

```
Low Resolution (64Ã—64):             High Resolution (512Ã—512):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   â”‚               â”‚                             â”‚
â”‚   [Blurry,        â”‚               â”‚   [Sharp, detailed image    â”‚
â”‚    pixelated      â”‚     â”€â”€â–º       â”‚    with realistic texture,  â”‚
â”‚    face]          â”‚   AI Magic    â”‚    pores, hair strands]     â”‚
â”‚                   â”‚               â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Traditional upscaling: Just makes pixels bigger (still blurry)
AI upscaling: Adds plausible detail that wasn't there!
```

<div class="warning">
**Ethical note:** Super resolution "hallucinates" detail. The added details are plausible but not necessarily accurate. Not suitable for forensics or legal evidence!
</div>

---

# ğŸ”¶ Domain 6: Self-Supervised Learning
## The Secret Sauce of Modern AI

*"Give me a lever long enough and I shall move the world."* â€” Archimedes

---

# The Self-Supervised Revolution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    THE LABELING BOTTLENECK                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   SUPERVISED LEARNING:                                              â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                â”‚
â”‚   Need millions of labeled examples                                  â”‚
â”‚   Labeling is EXPENSIVE and SLOW                                     â”‚
â”‚   Limited by human annotation capacity                               â”‚
â”‚                                                                      â”‚
â”‚   ImageNet: 14 million images                                       â”‚
â”‚   Cost: ~$500,000 and years of work!                                â”‚
â”‚                                                                      â”‚
â”‚   SELF-SUPERVISED LEARNING:                                         â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚   Create labels FROM the data itself                                 â”‚
â”‚   "Free" supervision from data structure                             â”‚
â”‚   Can use BILLIONS of examples                                       â”‚
â”‚                                                                      â”‚
â”‚   GPT-3: 45 TB of text                                              â”‚
â”‚   Cost: Compute only (no labeling!)                                  â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 26: Masked Language Modeling (BERT-style)

**What:** Predict the hidden word(s) â€” fill in the blank.

```
Training example:

Original:  "The cat sat on the mat."
Masked:    "The cat sat on the [MASK]."
                                  â”‚
                                  â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚      BERT       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
Predictions:    "mat"   (0.45)  â† Correct!
                "floor" (0.22)
                "couch" (0.15)
                "bed"   (0.08)
                ...
```

<div class="insight">
BERT was trained on **3.3 billion words** from Wikipedia and books, just playing fill-in-the-blank!
</div>

---

# Task 27: Next Token Prediction (GPT-style)

**What:** Predict what comes next in a sequence.

```
Input:  "The capital of France is"
                                  â”‚
                                  â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚      GPT        â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
Next token distribution:
         "Paris"  (0.89)  â† Most likely
         "the"    (0.03)
         "in"     (0.02)
         "a"      (0.01)
         ...
```

<div class="insight">
**GPT, Claude, Gemini, and all LLMs** are trained with just this one objective â€” repeated trillions of times! The simplicity is the brilliance.
</div>

---

# BERT vs GPT: Key Differences

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BERT vs GPT                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   BERT (Bidirectional)              GPT (Autoregressive)            â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”‚
â”‚                                                                      â”‚
â”‚   "The [MASK] sat on mat"           "The cat sat on"â†’ "the"â†’ "mat"  â”‚
â”‚        â†‘â†“â†‘â†“â†‘                            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º        â”‚
â”‚   Looks both directions             Only looks backward             â”‚
â”‚                                                                      â”‚
â”‚   Best for:                         Best for:                       â”‚
â”‚   â€¢ Understanding text              â€¢ Generating text               â”‚
â”‚   â€¢ Classification                  â€¢ Chat/dialogue                 â”‚
â”‚   â€¢ Question answering              â€¢ Code completion               â”‚
â”‚   â€¢ Named entity recognition        â€¢ Creative writing              â”‚
â”‚                                                                      â”‚
â”‚   Can't generate text well          Can generate, but slower        â”‚
â”‚   (doesn't predict in order)        (one token at a time)           â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 28: Contrastive Learning

**What:** Learn that different views of the same image should have similar embeddings.

```
Original Image:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     ğŸ±      â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”      Create different "views"
    â–¼             â–¼      (augmentations)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ±      â”‚  â”‚    ğŸ±   â”‚
â”‚(cropped)â”‚  â”‚(rotated)â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚            â”‚
     â–¼            â–¼
   [emb1]      [emb2]      These should be SIMILAR!

Meanwhile: embeddings of DIFFERENT images should be DIFFERENT!

   [cat_emb] â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ [dog_emb]
              Push apart!
```

---

# Contrastive Learning: The Big Picture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONTRASTIVE LEARNING                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   Key Insight:                                                       â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                       â”‚
â”‚   We don't need labels to learn good representations!                â”‚
â”‚   Just need to know: "These are the same" vs "These are different"   â”‚
â”‚                                                                      â”‚
â”‚   Training:                                                          â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                          â”‚
â”‚   â€¢ Take image â†’ create 2 augmented versions (positive pair)         â”‚
â”‚   â€¢ Other images in batch = negative pairs                           â”‚
â”‚   â€¢ Learn: positives close, negatives far                            â”‚
â”‚                                                                      â”‚
â”‚   Result:                                                            â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€                                                            â”‚
â”‚   An encoder that maps similar images to similar embeddings          â”‚
â”‚   Can then use these embeddings for ANY downstream task!             â”‚
â”‚   Often matches supervised learning with just 1% of labels!          â”‚
â”‚                                                                      â”‚
â”‚   Famous methods: SimCLR, MoCo, CLIP                                 â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ”· Domain 7: Reinforcement Learning
## Learning by Doing

*"Experience is the teacher of all things."* â€” Julius Caesar

---

# The RL Framework

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    REINFORCEMENT LEARNING LOOP                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                    â”‚      ENVIRONMENT        â”‚                       â”‚
â”‚                    â”‚   (game, robot, world)  â”‚                       â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                               â”‚                                      â”‚
â”‚              State s          â”‚         Reward r                     â”‚
â”‚              (what agent      â”‚         (how good                    â”‚
â”‚               observes)       â”‚          was that?)                  â”‚
â”‚                    â”‚          â”‚              â”‚                       â”‚
â”‚                    â–¼          â”‚              â–¼                       â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚              â”‚             AGENT                  â”‚                  â”‚
â”‚              â”‚   (policy network: s â†’ action)     â”‚                  â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                               â”‚                                      â”‚
â”‚                          Action a                                    â”‚
â”‚                      (what agent does)                               â”‚
â”‚                               â”‚                                      â”‚
â”‚                               â–¼                                      â”‚
â”‚                         Loop forever!                                â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 29: Game Playing

**What:** Learn optimal strategy through trial and error.

```
Game State (Chess):              Agent Decision:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â™œ â™ â™ â™› â™š â™ â™ â™œ   â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â™Ÿ â™Ÿ â™Ÿ â™Ÿ â™Ÿ â™Ÿ â™Ÿ â™Ÿ   â”‚    â”€â”€â–º   â”‚  Best move:     â”‚
â”‚ . . . . . . . .   â”‚          â”‚  e2 â†’ e4        â”‚
â”‚ . . . . . . . .   â”‚          â”‚                 â”‚
â”‚ . . . . . . . .   â”‚          â”‚  Evaluation:    â”‚
â”‚ . . . . . . . .   â”‚          â”‚  +0.3 pawns     â”‚
â”‚ â™™ â™™ â™™ â™™ â™™ â™™ â™™ â™™   â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â™– â™˜ â™— â™• â™” â™— â™˜ â™–   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AlphaGo/AlphaZero: Learned by playing MILLIONS of games against itself!
No human games needed â€” pure self-play!
```

---

# RL Milestones in Games

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RL GAME-PLAYING ACHIEVEMENTS                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   1992: TD-Gammon                                                   â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚   Backgammon at world champion level                                 â”‚
â”‚   First major RL success!                                            â”‚
â”‚                                                                      â”‚
â”‚   2013: DQN (Atari)                                                 â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                   â”‚
â”‚   Superhuman at 29 Atari games                                       â”‚
â”‚   Raw pixels as input!                                               â”‚
â”‚                                                                      â”‚
â”‚   2016: AlphaGo                                                     â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                   â”‚
â”‚   Beats world champion Lee Sedol at Go                               â”‚
â”‚   Game with 10^170 possible positions!                               â”‚
â”‚                                                                      â”‚
â”‚   2019: AlphaStar                                                   â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚   Grandmaster level at StarCraft II                                  â”‚
â”‚   Real-time, imperfect information, complex strategy                 â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 30: Robot Control

**What:** Learn to move and interact in the physical world.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚        ENVIRONMENT (Simulation or Real World)                       â”‚
â”‚                                                                     â”‚
â”‚             ğŸ¤– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º ğŸ¯                       â”‚
â”‚            Robot                          Goal                      â”‚
â”‚                                                                     â”‚
â”‚   Obstacles: ğŸ“¦  ğŸª‘  ğŸš§                                              â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–²                    â”‚
                    â”‚                    â”‚
            State (sensors,              Actions (motor
            camera, position)            commands: turn,
                    â”‚                    move, grip)
                    â”‚                    â”‚
                    â”‚                    â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚          POLICY NETWORK             â”‚
              â”‚   (learned from many attempts)      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Reward: +10 for reaching goal, -1 for bumping, -0.01 per step
```

---

# Real-World RL Applications

<div class="columns">
<div>

**Robotics**
- Robot manipulation (picking objects)
- Drone navigation
- Self-balancing robots
- Walking robots (Boston Dynamics)

**Games**
- Video game AI
- Board game engines
- Game testing automation

</div>
<div>

**Beyond Games**
- **Data center cooling** (Google: 40% energy savings)
- **Chip design** (Google, NVIDIA)
- **Trading** (quantitative finance)
- **Recommendations** (long-term engagement)
- **RLHF** (making LLMs helpful & safe!)

</div>
</div>

<div class="insight">
**ChatGPT uses RLHF** (Reinforcement Learning from Human Feedback) to learn to be helpful rather than just predicting text!
</div>

---

# ğŸ”¶ Domain 8: Multimodal Tasks
## Combining Vision + Language

*"The whole is greater than the sum of its parts."* â€” Aristotle

---

# The Multimodal Revolution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MULTIMODAL = MULTIPLE MODALITIES                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   MODALITY = Type of data                                           â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                            â”‚
â”‚   â€¢ Text (words, sentences)                                          â”‚
â”‚   â€¢ Images (photos, diagrams)                                        â”‚
â”‚   â€¢ Audio (speech, music)                                            â”‚
â”‚   â€¢ Video (sequences of images + audio)                              â”‚
â”‚                                                                      â”‚
â”‚   MULTIMODAL MODELS:                                                â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚
â”‚   â€¢ GPT-4V: Text + Images                                           â”‚
â”‚   â€¢ Gemini: Text + Images + Audio + Video                           â”‚
â”‚   â€¢ CLIP: Connects text and images                                   â”‚
â”‚   â€¢ Claude: Text + Images + Documents                                â”‚
â”‚                                                                      â”‚
â”‚   The trend: One model to rule them all!                             â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 31: Visual Question Answering (VQA)

**What:** Answer questions about images using both visual and language understanding.

```
Image:                              Questions & Answers:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       â”‚        Q: "How many people are
â”‚    ğŸ‘¨ ğŸ‘© ğŸ•              â”‚            in the image?"
â”‚                       â”‚        A: "Two people"
â”‚  [People walking      â”‚
â”‚   a dog in a park]    â”‚        Q: "What animal is there?"
â”‚                       â”‚        A: "A dog"
â”‚    ğŸŒ³      ğŸŒ³         â”‚
â”‚                       â”‚        Q: "What are they doing?"
â”‚                       â”‚        A: "Walking their dog
â”‚                       â”‚            in a park"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Requires BOTH:
- Understanding image content (computer vision)
- Understanding question (NLP)
- Reasoning to connect them!
```

---

# Task 32: Image Captioning

**What:** Generate natural language description of an image.

```
Image:                              Generated Caption:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       â”‚
â”‚   ğŸƒâ€â™‚ï¸ ğŸƒâ€â™€ï¸ ğŸƒ           â”‚   â”€â”€â–º   "A group of runners
â”‚                       â”‚          participating in a city
â”‚   [Marathon scene     â”‚          marathon on a sunny day,
â”‚    with crowds and    â”‚          with spectators cheering
â”‚    city buildings]    â”‚          along the street and tall
â”‚                       â”‚          buildings in the background."
â”‚   ğŸ‘¥ ğŸ‘¥ ğŸ‘¥ ğŸ‘¥ ğŸ¢ğŸ¢    â”‚
â”‚                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

The inverse of VQA:
Instead of answering questions, generate descriptions!
```

---

# Task 33: Text-to-Video

**What:** Generate video from text description.

```
Prompt: "A golden retriever running through a field
         of sunflowers on a sunny day, slow motion"
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Video Model    â”‚
            â”‚  (Sora, Runway, â”‚
            â”‚   Pika, etc.)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”
    â”‚Frame 1â”‚ â”‚Frame 2â”‚ â”‚Frame 3â”‚ â”‚Frame 4â”‚ ... â”‚Frame Nâ”‚
    â”‚  ğŸ•   â”‚ â”‚  ğŸ•   â”‚ â”‚  ğŸ•   â”‚ â”‚  ğŸ•   â”‚     â”‚  ğŸ•   â”‚
    â”‚ ğŸŒ»ğŸŒ»  â”‚ â”‚ ğŸŒ»ğŸŒ»  â”‚ â”‚ ğŸŒ»ğŸŒ»  â”‚ â”‚ ğŸŒ»ğŸŒ»  â”‚     â”‚ ğŸŒ»ğŸŒ»  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”˜

                  Temporally consistent video!
```

---

# CLIP: The Foundation of Multimodal AI

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLIP: Connecting Text and Images                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   Training Data: 400 million (image, caption) pairs from internet   â”‚
â”‚                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚   â”‚    Image    â”‚         â”‚    Text     â”‚                            â”‚
â”‚   â”‚   Encoder   â”‚         â”‚   Encoder   â”‚                            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚          â”‚                       â”‚                                   â”‚
â”‚          â–¼                       â–¼                                   â”‚
â”‚    [image_emb]   â†â”€ should match â”€â†’   [text_emb]                    â”‚
â”‚                                                                      â”‚
â”‚   "A dog playing     â†’    [0.23, -0.41, 0.87, ...]                  â”‚
â”‚    in the snow"           Shared embedding space!                    â”‚
â”‚                                                                      â”‚
â”‚   Result: Can search images with text, or text with images!          â”‚
â”‚   Powers: DALL-E, Stable Diffusion, image search, and more          â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ”· Domain 9: Tabular & Time Series
## The Classic ML Tasks

*"Not everything that counts can be counted, but data often helps."*

---

# Task 34-35: Regression & Classification on Tables

<div class="columns">
<div>

**Tabular Regression:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Beds   â”‚ SqFt â”‚ Price? â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3      â”‚ 1500 â”‚ ???    â”‚
â”‚ 4      â”‚ 2200 â”‚ ???    â”‚
â”‚ 2      â”‚ 900  â”‚ ???    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
   Predict: $425,000

Output: Continuous number
```

</div>
<div>

**Tabular Classification:**
```
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Age â”‚ Incomeâ”‚ Default?â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 35  â”‚ 75K   â”‚ ???     â”‚
â”‚ 52  â”‚ 120K  â”‚ ???     â”‚
â”‚ 28  â”‚ 45K   â”‚ ???     â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
   Predict: Yes / No

Output: Category
```

</div>
</div>

<div class="insight">
For tabular data, **gradient boosting (XGBoost, LightGBM)** often beats deep learning! Simpler, faster, and more interpretable.
</div>

---

# Task 36: Time Series Forecasting

**What:** Predict future values from historical patterns.

```
Historical Data:                         Forecast:
                                              â•±â•²?
Sales                                        â•±  ?
  â†‘                                         â•±   ?
  â”‚    â•±â•²    â•±â•²    â•±â•²    â•±â•²              â•±
  â”‚   â•±  â•²  â•±  â•²  â•±  â•²  â•±  â•²           â•±
  â”‚  â•±    â•²â•±    â•²â•±    â•²â•±    â•²        â•±â•±
  â”‚ â•±                        â•²      â•±
  â”‚â•±                          â•²   â•±
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
  Jan  Mar  May  Jul  Sep  Nov â”‚ Jan  Mar  May
                               â”‚
                         Today â”‚    Future
                               â”‚   (prediction)

Components to model:
â€¢ Trend (overall direction)
â€¢ Seasonality (repeating patterns)
â€¢ Noise (random variation)
```

---

# Time Series: Key Patterns

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TIME SERIES COMPONENTS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  TREND: Long-term direction                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚  â”‚            â•±                â”‚  Upward trend                       â”‚
â”‚  â”‚           â•±                 â”‚  (e.g., company growth)             â”‚
â”‚  â”‚          â•±                  â”‚                                     â”‚
â”‚  â”‚        â•±                    â”‚                                     â”‚
â”‚  â”‚      â•±                      â”‚                                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚                                                                      â”‚
â”‚  SEASONALITY: Repeating patterns                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚  â”‚  â•±â•²    â•±â•²    â•±â•²    â•±â•²      â”‚  Weekly, monthly, yearly            â”‚
â”‚  â”‚ â•±  â•²  â•±  â•²  â•±  â•²  â•±  â•²     â”‚  (e.g., holiday shopping)          â”‚
â”‚  â”‚â•±    â•²â•±    â•²â•±    â•²â•±    â•²    â”‚                                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Task 37: Recommendation Systems

**What:** Predict what users will like based on their history.

```
User-Item Matrix:                    Recommendations:
                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         Movie1 Movie2 Movie3 Movie4 â”‚ For User A:          â”‚
User A    â­â­â­â­â­   ?    â­â­â­   ?    â”‚  â€¢ Movie2 (pred: 4.2)â”‚
User B    â­â­â­â­  â­â­â­â­â­  ?    â­â­  â”‚  â€¢ Movie4 (pred: 3.8)â”‚
User C     ?    â­â­â­â­  â­â­â­â­â­ â­â­â­ â”‚                      â”‚
                                     â”‚ "Because you liked   â”‚
                                     â”‚  Movie1 and Movie3"  â”‚
                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Two main approaches:
â€¢ Collaborative: "Users like you also liked..."
â€¢ Content-based: "Similar items to ones you liked..."
```

---

# Recommendation: The Netflix Problem

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RECOMMENDATION CHALLENGES                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  THE COLD START PROBLEM:                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚  New user: No history â†’ What to recommend?                          â”‚
â”‚  New item: No ratings â†’ Who might like it?                          â”‚
â”‚  Solution: Ask preferences, use demographics, popular items          â”‚
â”‚                                                                      â”‚
â”‚  THE SPARSITY PROBLEM:                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚  Netflix: 200M users Ã— 15K movies = 3 trillion possible ratings     â”‚
â”‚  Actual ratings: ~5 billion â†’ 0.17% filled!                         â”‚
â”‚  Solution: Matrix factorization, embeddings                          â”‚
â”‚                                                                      â”‚
â”‚  THE FILTER BUBBLE:                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚  Only showing similar content â†’ User misses diverse content          â”‚
â”‚  Solution: Exploration vs exploitation, diversity metrics            â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Summary: The ML Task Landscape

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ML TASK FAMILIES                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  SUPERVISED             UNSUPERVISED        SELF-SUPERVISED          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚
â”‚  â€¢ Classification       â€¢ Clustering        â€¢ Masked LM (BERT)       â”‚
â”‚  â€¢ Regression           â€¢ Dim. Reduction    â€¢ Next Token (GPT)       â”‚
â”‚  â€¢ Detection            â€¢ Anomaly Det.      â€¢ Contrastive (CLIP)     â”‚
â”‚  â€¢ Segmentation                                                      â”‚
â”‚  â€¢ Seq2Seq                                                           â”‚
â”‚                                                                      â”‚
â”‚  GENERATIVE             REINFORCEMENT       MULTIMODAL               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚
â”‚  â€¢ Image Gen            â€¢ Game Playing      â€¢ VQA                    â”‚
â”‚  â€¢ Text Gen             â€¢ Robotics          â€¢ Captioning             â”‚
â”‚  â€¢ Video Gen            â€¢ RLHF              â€¢ Text-to-Image          â”‚
â”‚  â€¢ Style Transfer                           â€¢ Text-to-Video          â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Choosing the Right Task

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DECISION FLOWCHART                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   What do you want to predict?                                       â”‚
â”‚              â”‚                                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚   â–¼          â–¼          â–¼            â–¼                               â”‚
â”‚ Category  Continuous  Location     New Content                       â”‚
â”‚   â”‚         â”‚           â”‚             â”‚                              â”‚
â”‚   â–¼         â–¼           â–¼             â–¼                              â”‚
â”‚ Classification Regression Detection  Generation                     â”‚
â”‚                                                                      â”‚
â”‚   Have labels?                                                       â”‚
â”‚   â”œâ”€â”€ Yes â†’ Supervised                                               â”‚
â”‚   â”œâ”€â”€ No  â†’ Unsupervised (clustering, anomaly)                       â”‚
â”‚   â””â”€â”€ Can create from data â†’ Self-supervised                        â”‚
â”‚                                                                      â”‚
â”‚   Need to take actions?                                              â”‚
â”‚   â””â”€â”€ Yes â†’ Reinforcement Learning                                   â”‚
â”‚                                                                      â”‚
â”‚   Multiple input types?                                              â”‚
â”‚   â””â”€â”€ Yes â†’ Multimodal                                               â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Key Takeaways

### The 5 Things to Remember

1. **Every task = Input type + Output type**
   Define these clearly and you've defined your problem

2. **Same architectures work across domains**
   Transformers power text, images, audio, and more

3. **Self-supervised learning powers modern AI**
   GPT, BERT, CLIP â€” all learned from unlabeled data

4. **Start with the task â†’ then choose the model**
   Don't pick a model first and force it to fit

5. **Real-world ML often combines multiple tasks**
   Self-driving cars: detection + segmentation + prediction + control

---

# The ML Practitioner's Toolkit

| Task Type | Go-To Models (2024) |
|-----------|-------------------|
| Image Classification | ResNet, EfficientNet, ViT |
| Object Detection | YOLOv8, DETR, RT-DETR |
| Segmentation | SAM, Mask R-CNN |
| Text Classification | BERT, RoBERTa |
| Text Generation | GPT-4, Claude, Llama |
| Speech-to-Text | Whisper |
| Image Generation | Stable Diffusion, DALL-E |
| Tabular | XGBoost, LightGBM, TabNet |
| Time Series | Prophet, N-BEATS, TimeGPT |
| Recommendations | Two-Tower, DLRM |

---

# What's Next?

<div class="columns">
<div>

**In the Labs:**
- Lab 1-2: sklearn basics
- Lab 3: PyTorch & neural nets
- Lab 4-5: Build your own LLM
- Lab 6-7: Object detection

</div>
<div>

**The Bigger Picture:**
- Most tasks share core principles
- Transfer learning is key
- Start simple, add complexity
- The best model is the one you ship!

</div>
</div>

<div class="insight">
Pick a task, find a dataset, and start building! The best way to learn ML is by doing.
</div>

---

# Thank You!

**"The best way to predict the future is to invent it."** â€” Alan Kay

### Resources
- Papers With Code (paperwithcode.com) â€” State-of-the-art models
- Hugging Face (huggingface.co) â€” Pre-trained models
- Kaggle (kaggle.com) â€” Datasets and competitions

## Questions?

---
