# Mean Average Precision (mAP)

direction: down

title: {
  label: Mean Average Precision (mAP)
  near: top-center
  shape: text
  style.font-size: 24
  style.bold: true
}

step1: {
  label: |md
    **Step 1: Compute Precision-Recall Curve**
    For each class, vary confidence threshold from 1.0 → 0.0
    Plot Precision vs Recall at each threshold
  |
  shape: rectangle
  style.fill: "#E3F2FD"
  style.stroke: "#2E86AB"
  style.stroke-width: 2
}

step2: {
  label: |md
    **Step 2: Compute AP (Average Precision)**
    AP = Area Under the PR Curve
    (Typically using 11-point or all-point interpolation)
  |
  shape: rectangle
  style.fill: "#E8F5E9"
  style.stroke: "#06A77D"
  style.stroke-width: 2
}

step3: {
  label: |md
    **Step 3: Average Across Classes**
    mAP = (AP_dog + AP_cat + AP_car + ...) / N_classes
  |
  shape: rectangle
  style.fill: "#FFF3E0"
  style.stroke: "#E65100"
  style.stroke-width: 2
}

variants: {
  direction: right

  map50: {
    label: |md
      **mAP@0.5**
      IoU threshold = 0.5
      (PASCAL VOC style)
    |
    shape: rectangle
    style.fill: "#FFF9C4"
  }

  map5095: {
    label: |md
      **mAP@0.5:0.95**
      Average over
      IoU = 0.5, 0.55, ..., 0.95
      (COCO style - stricter)
    |
    shape: rectangle
    style.fill: "#FFECB3"
  }
}

step1 -> step2 -> step3 -> variants

scores: {
  label: |md
    **Typical Scores (COCO mAP@0.5:0.95)**
    • YOLOv5s: ~36 (fast, small)
    • YOLOv5x: ~50 (accurate, large)
    • YOLOv8x: ~53 (latest)
  |
  shape: rectangle
  style.fill: "#ECEFF1"
  style.stroke: "#607D8B"
}

variants -> scores
