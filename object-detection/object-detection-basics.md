---
marp: true
theme: default
paginate: true
backgroundColor: #fff
style: |
  section {
    font-family: 'Segoe UI', 'Arial', sans-serif;
    font-size: 23px;
    padding: 35px;
    color: #333;
  }
  h1 { color: #2E86AB; font-size: 1.7em; margin-bottom: 0.2em; }
  h2 { color: #06A77D; font-size: 1.1em; margin-top: 0; }
  h3 { color: #457B9D; font-size: 1.0em; }
  strong { color: #D62828; }
  code {
    background: #f4f4f4;
    color: #2E86AB;
    padding: 2px 6px;
    border-radius: 4px;
    font-family: 'Consolas', 'Monaco', monospace;
  }
  pre {
    background: #f8f9fa;
    border-radius: 8px;
    padding: 12px;
    font-size: 0.78em;
    line-height: 1.3;
    overflow: hidden;
  }
  .example {
    background: linear-gradient(135deg, #e8f5e9 0%, #c8e6c9 100%);
    border-left: 4px solid #06A77D;
    padding: 10px 12px;
    margin: 8px 0;
    border-radius: 0 6px 6px 0;
  }
  .insight {
    background: #fff3cd;
    border-left: 4px solid #ffc107;
    padding: 10px 12px;
    margin: 8px 0;
    border-radius: 0 6px 6px 0;
  }
  .warning {
    background: #ffebee;
    border-left: 4px solid #D62828;
    padding: 10px 12px;
    margin: 8px 0;
    border-radius: 0 6px 6px 0;
  }
  .columns { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; }
  table { font-size: 0.85em; width: 100%; }
  th { background: #2E86AB; color: white; padding: 6px; }
  td { padding: 6px; border-bottom: 1px solid #dee2e6; }
---

# Object Detection Basics
## Deep Learning for Computer Vision

**Nipun Batra** Â· IIT Gandhinagar
*Inspired by Andrew Ng's teaching style*

---

# What You Will Learn Today

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚   Part 1: The Core Problem                                      â”‚
â”‚           Classification vs Detection vs Segmentation           â”‚
â”‚                                                                 â”‚
â”‚   Part 2: Bounding Boxes                                        â”‚
â”‚           How we represent object locations                     â”‚
â”‚                                                                 â”‚
â”‚   Part 3: IoU (Intersection over Union)                         â”‚
â”‚           How we measure detection quality                      â”‚
â”‚                                                                 â”‚
â”‚   Part 4: NMS (Non-Maximum Suppression)                         â”‚
â”‚           How we clean up duplicate detections                  â”‚
â”‚                                                                 â”‚
â”‚   Part 5: Architectures (YOLO, Faster R-CNN)                    â”‚
â”‚           How modern detectors work                             â”‚
â”‚                                                                 â”‚
â”‚   Part 6: Training & Metrics (mAP)                              â”‚
â”‚           How we train and evaluate detectors                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Part 1: The Core Problem
## What IS Object Detection?

---

# Classification vs Detection

```
CLASSIFICATION:                    DETECTION:
"What is in this image?"           "What is here AND where?"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     â”‚            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚     ğŸ•              â”‚            â”‚  â”‚ DOG    â”‚         â”‚
â”‚                     â”‚  â”€â”€â”€â–º      â”‚  â”‚ 0.95   â”‚         â”‚
â”‚                     â”‚            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                  â”‚
        â–¼                                  â–¼
   Output: "Dog"                  Output: "Dog" at (10,20,80,90)
   (one label)                    (label + bounding box)
```

<div class="insight">
Detection = Classification + Localization
</div>

---

# The Full Vision Hierarchy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLASSIFICATION                                                  â”‚
â”‚                                                                 â”‚
â”‚   Input: Image                Output: Single Label              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚   â”‚  ğŸ•  ğŸˆ     â”‚  â”€â”€â”€â”€â”€â”€â”€â–º   ["Dog", "Cat"]                   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DETECTION                                                       â”‚
â”‚                                                                 â”‚
â”‚   Input: Image                Output: Labels + Boxes            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             [("Dog", 10,20,80,90),           â”‚
â”‚   â”‚ â”Œâ”€â”€â”  â”Œâ”€â”€â”  â”‚  â”€â”€â”€â”€â”€â”€â”€â–º    ("Cat", 100,30,60,70)]          â”‚
â”‚   â”‚ â”‚ğŸ•â”‚  â”‚ğŸˆâ”‚  â”‚                                               â”‚
â”‚   â”‚ â””â”€â”€â”˜  â””â”€â”€â”˜  â”‚                                               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SEGMENTATION                                                    â”‚
â”‚                                                                 â”‚
â”‚   Input: Image                Output: Pixel-wise Labels         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚   â”‚  ğŸ•  ğŸˆ     â”‚  â”€â”€â”€â”€â”€â”€â”€â–º   â”‚ DDDD CCCCC  â”‚  D=Dog, C=Cat    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚ DDDD CCCCC  â”‚                   â”‚
â”‚                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Real-World Detection Examples

<div class="columns">
<div>

**Self-Driving Cars:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸš—  ğŸš¶  ğŸš¦            â”‚
â”‚  [car] [person] [light] â”‚
â”‚   0.97   0.89    0.95   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Detect: cars, pedestrians,
traffic signs, lanes
```

**Retail:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“¦  ğŸ“¦  ğŸ“¦             â”‚
â”‚ [milk][bread][eggs]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Detect: products on shelves
for inventory management
```

</div>
<div>

**Medical Imaging:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         â”‚
â”‚      â—‹ [tumor 0.87]     â”‚
â”‚                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Detect: tumors, lesions,
abnormalities in X-rays
```

**Security:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ‘¤  ğŸ‘¤  ğŸ‘¤  ğŸ“¦        â”‚
â”‚ [face] [face] [package] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Detect: faces, unattended
bags, suspicious activity
```

</div>
</div>

---

# Part 2: Bounding Boxes
## How We Represent Locations

---

# Bounding Box Basics

A bounding box is a **rectangle** that tightly contains an object.

```
Image Coordinate System:

    (0,0) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º x (width)
      â”‚
      â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚    â”‚                     â”‚
      â”‚    â”‚     ğŸ•              â”‚ â† Object inside box
      â”‚    â”‚                     â”‚
      â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
    y (height)

Box is defined by 4 numbers: Where does it start? How big is it?
```

---

# Bounding Box Formats

<div class="warning">
Different datasets/frameworks use different formats!
</div>

```
FORMAT 1: (x, y, width, height)              FORMAT 2: (x1, y1, x2, y2)
"Top-left corner + size"                     "Two opposite corners"

   (x, y)                                       (x1, y1)
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                 â”‚                          â”‚                 â”‚
     â”‚      ğŸ•         â”‚ height                   â”‚      ğŸ•         â”‚
     â”‚                 â”‚                          â”‚                 â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           width                                                  (x2, y2)

Example: (50, 100, 200, 150)                 Example: (50, 100, 250, 250)

FORMAT 3: (cx, cy, width, height)
"Center point + size" (used by YOLO)

              width
         â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â†‘
       â”‚                 â”‚  â”‚
       â”‚    â— (cx,cy)    â”‚  â”‚ height
       â”‚                 â”‚  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â†“
```

---

# Normalized vs Absolute Coordinates

```
ABSOLUTE (Pixels):                    NORMALIZED (0-1 range):

Image: 640Ã—480 pixels                 Image: Any size â†’ values 0-1

Box: (100, 50, 200, 150)              Box: (0.156, 0.104, 0.312, 0.312)
     â†‘    â†‘   â†‘    â†‘                       â†‘      â†‘      â†‘      â†‘
     â”‚    â”‚   â”‚    â””â”€ height 150px         â”‚      â”‚      â”‚      â””â”€ h/H
     â”‚    â”‚   â””â”€ width 200px               â”‚      â”‚      â””â”€ w/W
     â”‚    â””â”€ y = 50px                      â”‚      â””â”€ y/H
     â””â”€ x = 100px                          â””â”€ x/W

Conversion:
x_norm = x_abs / image_width
y_norm = y_abs / image_height
```

<div class="insight">
Normalized coordinates are **resolution-independent** â€” the same box
works for any image size!
</div>

---

# Part 3: IoU
## How Good Is a Detection?

---

# The Problem: When Is a Box "Correct"?

```
Ground Truth (what a human labeled):    Model Prediction:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       â”‚               â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚               â”‚   â”‚            â”‚      â”‚
â”‚  â”‚    ğŸ•       â”‚      â”‚               â”‚   â”‚   ğŸ•       â”‚      â”‚
â”‚  â”‚             â”‚      â”‚               â”‚   â”‚            â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚               â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                       â”‚               â”‚                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Is this prediction "correct"?

- Boxes aren't identical, but they overlap a lot
- We need a NUMBER to measure how good this is
- That number is IoU (Intersection over Union)
```

---

# IoU: The Formula

```
                    Area of Overlap
        IoU = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                 Area of Union

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚   Ground Truth        Prediction        Overlap (Intersection) â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚   â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚    +     â”‚â–“â–“â–“â–“â–“â–“â–“â–“â”‚   =    â”‚â–’â–’â–’â–’â–’â–’â–’â–’â”‚             â”‚
â”‚   â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚          â”‚â–“â–“â–“â–“â–“â–“â–“â–“â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                                                                 â”‚
â”‚   Union = All area covered by EITHER box (not double-counted)  â”‚
â”‚                                                                 â”‚
â”‚   Union = Area(GT) + Area(Pred) - Intersection                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# IoU: Visual Examples

```
CASE 1: Perfect Match              CASE 2: Good Overlap
        IoU = 1.0                          IoU â‰ˆ 0.7

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚ â† Boxes             â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚â–“â–“â–“â”‚
    â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚   identical         â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚â–“â–“â–“â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”˜
                                            â†‘
                                      Partial overlap

CASE 3: Poor Overlap               CASE 4: No Overlap
        IoU â‰ˆ 0.2                          IoU = 0.0

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”
    â”‚â–ˆâ–ˆâ–ˆâ”‚â–“â–“â–“â”‚â–“â–“â–“â”‚                     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚    â”‚â–“â–“â–“â–“â–“â–“â–“â”‚
    â”‚â–ˆâ–ˆâ–ˆâ”‚â–“â–“â–“â”‚â–“â–“â–“â”‚                     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚    â”‚â–“â–“â–“â–“â–“â–“â–“â”‚
    â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”˜
           â†‘                                 â†‘           â†‘
     Small overlap                     Ground Truth  Prediction
```

---

# IoU Thresholds in Practice

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   IoU Value   â”‚   Interpretation                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   1.0         â”‚   Perfect match (never happens in practice)     â”‚
â”‚   0.75+       â”‚   Excellent detection                           â”‚
â”‚   0.50        â”‚   Standard threshold for "correct" (COCO)       â”‚
â”‚   0.25        â”‚   Loose match (used in some old benchmarks)     â”‚
â”‚   0.0         â”‚   No overlap at all                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Common Rule:
    If IoU â‰¥ 0.5 â†’ Detection is a TRUE POSITIVE (TP) âœ“
    If IoU < 0.5 â†’ Detection is a FALSE POSITIVE (FP) âœ—
```

<div class="insight">
Different competitions use different thresholds:
- PASCAL VOC: IoU â‰¥ 0.5
- COCO: Multiple thresholds (0.5, 0.55, ..., 0.95)
</div>

---

# Part 4: Non-Maximum Suppression
## Cleaning Up Duplicate Detections

---

# The Problem: Too Many Boxes!

```
What the detector produces:              What we actually want:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚           â”‚                           â”‚
â”‚ â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”             â”‚           â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚ â”‚â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”            â”‚           â”‚  â”‚    ğŸ•       â”‚          â”‚
â”‚ â”‚â”‚â”‚   ğŸ•     â”‚ 0.95       â”‚   â”€â”€â”€â–º    â”‚  â”‚    0.95     â”‚          â”‚
â”‚ â”‚â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ 0.90       â”‚    NMS    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚ â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ 0.85       â”‚           â”‚                           â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ 0.80       â”‚           â”‚                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Detector found the SAME dog 4 times with slightly different boxes!
We want to keep only the BEST one.
```

---

# NMS Algorithm: Step by Step

```
STEP 1: Sort all boxes by confidence (highest first)
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Box A: 0.95, Box B: 0.90, Box C: 0.85     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STEP 2: Pick the highest confidence box â†’ KEEP IT
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  KEEP: Box A (0.95)                        â”‚
        â”‚  Remaining: [Box B, Box C]                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STEP 3: Remove all remaining boxes that overlap
        too much with Box A (IoU > threshold)
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  IoU(A, B) = 0.85 > 0.5 â†’ REMOVE Box B     â”‚
        â”‚  IoU(A, C) = 0.70 > 0.5 â†’ REMOVE Box C     â”‚
        â”‚  Remaining: []                             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STEP 4: Repeat until no boxes remain

OUTPUT: [Box A] â€” just one clean detection!
```

---

# NMS: Visual Example

```
BEFORE NMS:                           AFTER NMS:

Person Detections:                    Final Detections:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚    â”‚                               â”‚
â”‚ â”‚ Person â”‚    â”‚ Person â”‚      â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚ â”‚  0.95  â”‚    â”‚  0.93  â”‚      â”‚    â”‚ â”‚ Person â”‚    â”‚ Person â”‚      â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â” â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”   â”‚    â”‚ â”‚  0.95  â”‚    â”‚  0.93  â”‚      â”‚
â”‚ â”‚ Person    â”‚ â”‚ Person    â”‚   â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚ â”‚   0.88    â”‚ â”‚   0.85    â”‚   â”‚    â”‚                               â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚  Two people â†’ Two boxes!      â”‚
â”‚                               â”‚    â”‚                               â”‚
â”‚  4 overlapping boxes          â”‚    â”‚                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NMS keeps the best box per object, removes duplicates.
Boxes of DIFFERENT objects (low IoU) are both kept!
```

---

# NMS: The Python Pseudocode

```python
def nms(boxes, scores, iou_threshold=0.5):
    """
    boxes: List of (x1, y1, x2, y2)
    scores: Confidence for each box
    """
    # Sort by confidence (descending)
    order = scores.argsort()[::-1]

    keep = []

    while order.size > 0:
        # Pick the best box
        i = order[0]
        keep.append(i)

        # Compute IoU with remaining boxes
        ious = compute_iou(boxes[i], boxes[order[1:]])

        # Keep only boxes with IoU below threshold
        remaining = np.where(ious <= iou_threshold)[0]
        order = order[remaining + 1]

    return keep
```

---

# Part 5: How Detectors Work
## Two Main Approaches

---

# One-Stage vs Two-Stage Detectors

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TWO-STAGE (Faster R-CNN)                                        â”‚
â”‚                                                                 â”‚
â”‚   Image â”€â”€â–º Region Proposal â”€â”€â–º Classify & Refine â”€â”€â–º Output   â”‚
â”‚             Network (RPN)        each region                    â”‚
â”‚                                                                 â”‚
â”‚   Step 1: "Where might objects be?" (propose ~2000 regions)    â”‚
â”‚   Step 2: "What is each region?" (classify each one)           â”‚
â”‚                                                                 â”‚
â”‚   âœ“ More accurate   âœ— Slower                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ONE-STAGE (YOLO, SSD)                                           â”‚
â”‚                                                                 â”‚
â”‚   Image â”€â”€â–º Single Network â”€â”€â–º All boxes + classes at once!    â”‚
â”‚                                                                 â”‚
â”‚   Look at image once, predict everything in one pass            â”‚
â”‚                                                                 â”‚
â”‚   âœ“ Very fast (real-time)   âœ— Slightly less accurate          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# YOLO: You Only Look Once

**Core Idea:** Divide image into grid, predict boxes for each cell.

```
Input Image:              Grid (7Ã—7):              Predictions per cell:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚      â”‚   â”‚   â”‚ â— â”‚   â”‚       â”‚ For each grid cell: â”‚
â”‚      ğŸ•         â”‚  â”€â”€â–º â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  â”€â”€â–º  â”‚ â€¢ 2 bounding boxes  â”‚
â”‚                 â”‚      â”‚   â”‚   â”‚   â”‚   â”‚       â”‚ â€¢ Confidence scores â”‚
â”‚                 â”‚      â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤       â”‚ â€¢ Class probs       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚   â”‚   â”‚   â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜
                               â–²
                         Dog's center falls
                         in this cell â†’ this
                         cell predicts the dog!
```

Each cell is "responsible" for objects whose **center** falls inside it.

---

# YOLO: What Each Cell Predicts

```
Each grid cell outputs:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚   BOX 1:  [x, y, w, h, confidence]    (5 numbers)              â”‚
â”‚   BOX 2:  [x, y, w, h, confidence]    (5 numbers)              â”‚
â”‚   CLASS:  [P(dog), P(cat), P(car), ...] (C numbers)            â”‚
â”‚                                                                 â”‚
â”‚   Total per cell: 2Ã—5 + C = 10 + C numbers                     â”‚
â”‚   For 7Ã—7 grid with 20 classes: 7 Ã— 7 Ã— (10 + 20) = 1470       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Confidence = P(object exists) Ã— IoU(pred, truth)

If confidence is low â†’ "nothing interesting here"
If confidence is high â†’ "I found something!"
```

---

# YOLO Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       YOLO Architecture                         â”‚
â”‚                                                                 â”‚
â”‚   Input: 448Ã—448Ã—3 (RGB image)                                  â”‚
â”‚      â”‚                                                          â”‚
â”‚      â–¼                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚   â”‚ BACKBONE (Feature Extractor)            â”‚                   â”‚
â”‚   â”‚ 24 Convolutional Layers                 â”‚                   â”‚
â”‚   â”‚ Extract patterns: edges â†’ shapes â†’ partsâ”‚                   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                        â”‚                                        â”‚
â”‚                        â–¼                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚   â”‚ DETECTION HEAD                          â”‚                   â”‚
â”‚   â”‚ 2 Fully Connected Layers                â”‚                   â”‚
â”‚   â”‚ Output: 7Ã—7Ã—30 tensor                   â”‚                   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                        â”‚                                        â”‚
â”‚                        â–¼                                        â”‚
â”‚   Output: 7Ã—7 grid, each cell predicts 2 boxes + 20 classes    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Anchor Boxes: Better Shape Priors

**Problem:** A grid cell might contain multiple objects.
**Solution:** Use multiple "anchor boxes" of different shapes.

```
Without Anchors:                   With Anchors:

Cell predicts ONE box shape        Cell predicts MULTIPLE shapes
                                   matched to anchor templates
     â”Œâ”€â”€â”€â”
     â”‚   â”‚ â† Only one shape       â”Œâ”€â”€â”€â” â”œâ”€â”€â”€â”€â”€â”€â”€â” â•­â”€â”€â”€â”€â”€â”€â”€â•®
     â”‚   â”‚                        â”‚   â”‚ â”‚       â”‚ â”‚       â”‚
     â””â”€â”€â”€â”˜                        â””â”€â”€â”€â”˜ â”œâ”€â”€â”€â”€â”€â”€â”€â”˜ â•°â”€â”€â”€â”€â”€â”€â”€â•¯
                                    â†‘       â†‘         â†‘
                                  Tall   Wide     Square

Common anchor ratios: 1:1, 1:2, 2:1
Common scales: small, medium, large
```

<div class="insight">
Modern YOLO (v3+) uses 9 anchors: 3 scales Ã— 3 aspect ratios!
</div>

---

# Part 6: Training & Evaluation
## How We Measure Success

---

# The Loss Function

Detection models optimize multiple objectives simultaneously:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚   Total Loss = Î»â‚ Ã— Box Loss                                    â”‚
â”‚              + Î»â‚‚ Ã— Objectness Loss                             â”‚
â”‚              + Î»â‚ƒ Ã— Classification Loss                         â”‚
â”‚                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   BOX LOSS:           "How accurate are the coordinates?"       â”‚
â”‚   (x, y, w, h)        MSE or IoU-based loss                     â”‚
â”‚                                                                 â”‚
â”‚   OBJECTNESS LOSS:    "Does this cell contain an object?"       â”‚
â”‚   (confidence)        Binary cross-entropy                      â”‚
â”‚                                                                 â”‚
â”‚   CLASSIFICATION:     "What class is this object?"              â”‚
â”‚   (class probs)       Cross-entropy over classes                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Precision and Recall

```
PRECISION: "When I say 'dog', am I right?"

                True Positives
Precision = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            True Positives + False Positives

   TP: Correctly detected dogs
   FP: Non-dogs mistakenly called dogs

RECALL: "Did I find all the dogs?"

             True Positives
Recall = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         True Positives + False Negatives

   TP: Correctly detected dogs
   FN: Dogs that I missed
```

<div class="insight">
High precision = Few false alarms
High recall = Few missed objects
We want BOTH to be high!
</div>

---

# Precision-Recall Tradeoff

```
Confidence Threshold: "Only report if confidence > threshold"

HIGH THRESHOLD (0.9):                LOW THRESHOLD (0.3):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           â”‚       â”‚ â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â” â”‚
â”‚       â”Œâ”€â”€â”€â”               â”‚       â”‚ â”‚dogâ”‚â”‚dogâ”‚â”‚dogâ”‚â”‚???â”‚â”‚???â”‚ â”‚
â”‚       â”‚dogâ”‚               â”‚       â”‚ â”‚.95â”‚â”‚.80â”‚â”‚.60â”‚â”‚.40â”‚â”‚.35â”‚ â”‚
â”‚       â”‚.95â”‚               â”‚       â”‚ â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜ â”‚
â”‚       â””â”€â”€â”€â”˜               â”‚       â”‚                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Precision: High (few FP)            Precision: Low (some FP)
Recall: Low (missed some)           Recall: High (found most)

                    Precision
                    â†‘
               1.0  â”‚â—
                    â”‚ â•²
                    â”‚  â•²      â† PR Curve
                    â”‚   â•²
                    â”‚    â—
                    â”‚     â•²
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Recall
                         1.0
```

---

# Mean Average Precision (mAP)

```
STEP 1: For each class, compute Precision-Recall curve

        Precision
           â†‘
      1.0  â”‚â—â”€â”€â—
           â”‚    â•²
           â”‚     â—â”€â”€â—
           â”‚         â•²
           â”‚          â—â”€â”€â—
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Recall
                          1.0

STEP 2: Compute Area Under Curve (AP) for this class
        AP = Average precision across all recall levels

STEP 3: Average across all classes
        mAP = (AP_dog + AP_cat + AP_car + ...) / num_classes

mAP@0.5 = mAP computed with IoU threshold 0.5
mAP@0.5:0.95 = Average mAP across thresholds 0.5, 0.55, ..., 0.95
```

---

# mAP: A Concrete Example

```
Dataset: 100 dog images, model makes predictions

At confidence threshold = 0.9:
â”œâ”€ Found: 30 dogs correctly (TP = 30)
â”œâ”€ Missed: 70 dogs (FN = 70)
â”œâ”€ False alarms: 2 (FP = 2)
â”œâ”€ Precision = 30/(30+2) = 0.94
â””â”€ Recall = 30/(30+70) = 0.30

At confidence threshold = 0.5:
â”œâ”€ Found: 80 dogs correctly (TP = 80)
â”œâ”€ Missed: 20 dogs (FN = 20)
â”œâ”€ False alarms: 15 (FP = 15)
â”œâ”€ Precision = 80/(80+15) = 0.84
â””â”€ Recall = 80/(80+20) = 0.80

AP â‰ˆ Area under the precision-recall curve created by
     varying the confidence threshold from 1.0 to 0.0
```

---

# Common Benchmarks & Scores

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dataset         â”‚  Details                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PASCAL VOC      â”‚  20 classes, ~10K images                   â”‚
â”‚                  â”‚  Uses mAP@0.5                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MS COCO         â”‚  80 classes, ~120K images                  â”‚
â”‚                  â”‚  Uses mAP@0.5:0.95 (stricter)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ImageNet Det    â”‚  200 classes, ~400K images                 â”‚
â”‚                  â”‚  Large-scale benchmark                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Modern YOLO scores:
â”œâ”€ YOLOv5s: ~36 mAP on COCO (fast, small)
â”œâ”€ YOLOv5x: ~50 mAP on COCO (accurate, large)
â””â”€ YOLOv8x: ~53 mAP on COCO (latest)
```

---

# Data Augmentation for Detection

```
IMPORTANT: When you transform the IMAGE, also transform the BOXES!

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HORIZONTAL FLIP:                                                â”‚
â”‚                                                                 â”‚
â”‚   Original:              Flipped:                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚   â”‚ â”Œâ”€â”€â”€â”        â”‚       â”‚        â”Œâ”€â”€â”€â” â”‚                       â”‚
â”‚   â”‚ â”‚ ğŸ•â”‚        â”‚  â”€â”€â–º  â”‚        â”‚ ğŸ•â”‚ â”‚                       â”‚
â”‚   â”‚ â””â”€â”€â”€â”˜        â”‚       â”‚        â””â”€â”€â”€â”˜ â”‚                       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚   Box: (10, 20, 60, 80)  Box: (W-70, 20, W-10, 80)             â”‚
â”‚                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Other augmentations:                                            â”‚
â”‚  â€¢ Random crop (with box adjustment)                            â”‚
â”‚  â€¢ Color jitter (no box change needed)                          â”‚
â”‚  â€¢ Mosaic: Combine 4 images (complex box handling)              â”‚
â”‚  â€¢ Mixup: Blend two images                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Summary: The Detection Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OBJECT DETECTION PIPELINE                    â”‚
â”‚                                                                 â”‚
â”‚   1. INPUT IMAGE                                                â”‚
â”‚      â””â”€â–º Resize to fixed size (e.g., 640Ã—640)                  â”‚
â”‚                                                                 â”‚
â”‚   2. BACKBONE (Feature Extraction)                              â”‚
â”‚      â””â”€â–º CNN extracts visual features                          â”‚
â”‚                                                                 â”‚
â”‚   3. DETECTION HEAD                                             â”‚
â”‚      â””â”€â–º Predict boxes + classes for each anchor               â”‚
â”‚                                                                 â”‚
â”‚   4. POST-PROCESSING                                            â”‚
â”‚      â”œâ”€â–º Filter by confidence threshold                        â”‚
â”‚      â””â”€â–º Apply NMS to remove duplicates                        â”‚
â”‚                                                                 â”‚
â”‚   5. OUTPUT                                                     â”‚
â”‚      â””â”€â–º List of (class, confidence, x1, y1, x2, y2)          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Key Takeaways

1. **Detection = Classification + Localization**
   Predict WHAT and WHERE

2. **Bounding Box formats vary**
   Always check: (x,y,w,h) vs (x1,y1,x2,y2) vs normalized

3. **IoU measures overlap quality**
   IoU â‰¥ 0.5 usually means "correct" detection

4. **NMS removes duplicate boxes**
   Keep best, remove overlapping

5. **YOLO is fast (one-stage)**
   Real-time detection on video

6. **mAP is the gold standard metric**
   Combines precision and recall across thresholds

---

# Getting Started: Try YOLO!

```python
# Install
pip install ultralytics

# Run in 3 lines!
from ultralytics import YOLO

model = YOLO('yolov8n.pt')  # Load pretrained model
results = model('your_image.jpg')  # Run detection
results[0].show()  # Display results

# Each detection has:
for box in results[0].boxes:
    print(f"Class: {box.cls}, Confidence: {box.conf}")
    print(f"Box: {box.xyxy}")  # x1, y1, x2, y2
```

---

# Thank You!

**"AI is the new electricity."** â€” Andrew Ng

The same ideas that power self-driving cars work for detecting
anything: faces, products, medical anomalies, defects...

## Questions?
